{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upi2EY4L9ei3"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbF2F2miAT4a"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GoogleCloudPlatform/python-docs-samples/blob/main/alloydb/notebooks/generate_batch_embeddings.ipynb)\n",
        "\n",
        "---\n",
        "# Introduction\n",
        "\n",
        "This notebook shows you how to batch generate vector embeddings and store them in an AlloyDB database.\n",
        "\n",
        "With the steps listed here, you can dynamically build a batch of text chunks to embed based on character length of the source data in order to get more results per inference, leading to much more efficient embeddings generation. The process uses Asyncio to efficiently load the embeddings into AlloyDB after they are generated. These techniques can significantly speed up the process of generating large batches of embeddings and storing them in AlloyDB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbcZUjT1yvTq"
      },
      "source": [
        "## What you'll need\n",
        "\n",
        "* A Google Cloud Account and Google Cloud Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHdR4fF3vLWA"
      },
      "source": [
        "## Setup and Requirements\n",
        "\n",
        "In the following instructions you will learn to:\n",
        "\n",
        "1. Install required dependencies for our application\n",
        "2. Set up authentication for our project\n",
        "3. Set up a AlloyDB for PostgreSQL Instance\n",
        "4. Import the data used by our application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy9KqgPQ4GBi"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_ppDxYf4Gqs",
        "outputId": "6bf1f218-16dd-4e21-b312-0850e63ebc1e"
      },
      "outputs": [],
      "source": [
        "%pip install google-cloud-alloydb-connector[asyncpg]==1.4.0 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeUbHclxw7_l"
      },
      "source": [
        "### Authenticate to Google Cloud within Colab\n",
        "In order to access your Google Cloud Project from this notebook, you will need to Authenticate as an IAM user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_Q9hyqdyEx6l"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCiNGP1Qxd6x"
      },
      "source": [
        "### Connect Your Google Cloud Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLUGlG6UE2CK",
        "outputId": "d1bd6d3b-5db3-432c-9f2b-44aa2e510fc9"
      },
      "outputs": [],
      "source": [
        "# @markdown Please fill in the value below with your GCP project ID and then run the cell.\n",
        "\n",
        "# Please fill in these values.\n",
        "project_id = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# Quick input validations.\n",
        "assert project_id, \"⚠️ Please provide a Google Cloud project ID\"\n",
        "\n",
        "# Configure gcloud.\n",
        "!gcloud config set project {project_id}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-oqMC5Ox-ZM"
      },
      "source": [
        "### Enable APIs for AlloyDB and Vertex AI within your project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-bzfFb4A-xK"
      },
      "source": [
        "You will need to enable these APIs in order to create an AlloyDB database and utilize Vertex AI as an embeddings service!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKWrwyfzyTwH",
        "outputId": "73264ceb-d441-4aed-ab2b-961febc8ce29"
      },
      "outputs": [],
      "source": [
        "# enable GCP services\n",
        "!gcloud services enable alloydb.googleapis.com aiplatform.googleapis.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn8g7-wCyZU6"
      },
      "source": [
        "## Set up AlloyDB\n",
        "You will need a Postgres AlloyDB instance for the following stages of this notebook. Please set the following variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q2lc-Po1mPv",
        "outputId": "76c8466f-f865-4aa5-9ce8-b7b747480d74"
      },
      "outputs": [],
      "source": [
        "# @markdown Please fill in the both the Google Cloud region and name of your AlloyDB instance. Once filled in, run the cell.\n",
        "\n",
        "# Please fill in these values.\n",
        "region = \"\"  # @param {type:\"string\"}\n",
        "cluster_name = \"\"  # @param {type:\"string\"}\n",
        "instance_name = \"\"  # @param {type:\"string\"}\n",
        "database_name = \"testdb\"  # @param {type:\"string\"}\n",
        "table_name = \"investments\"\n",
        "password = input(\"Please provide a password to be used for 'postgres' database user: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XXI1uUu3y8gc"
      },
      "outputs": [],
      "source": [
        "# Quick input validations.\n",
        "assert region, \"⚠️ Please provide a Google Cloud region\"\n",
        "assert instance_name, \"⚠️ Please provide the name of your instance\"\n",
        "assert database_name, \"⚠️ Please provide the name of your database_name\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T616pEOUygYQ"
      },
      "source": [
        "### Create an AlloyDB Instance\n",
        "If you have already created an AlloyDB Cluster and Instance, you can skip these steps and skip to the Create a database section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyZYX4Jo1vfh"
      },
      "source": [
        "> ⏳ - Creating an AlloyDB cluster may take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQYni0NlTLzC"
      },
      "outputs": [],
      "source": [
        "# create the AlloyDB Cluster\n",
        "!gcloud beta alloydb clusters create {cluster_name} --password={password} --region={region}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8LkscYH5Vfp"
      },
      "source": [
        "Create an instance attached to our cluster with the following command.\n",
        "> ⏳ - Creating an AlloyDB instance may take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkqQSWoY5Kab",
        "outputId": "4f12cc52-3ea4-4da8-e488-81e74c426150"
      },
      "outputs": [],
      "source": [
        "!gcloud beta alloydb instances create {instance_name} --instance-type=PRIMARY --cpu-count=2 --region={region} --cluster={cluster_name}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXsQ1UJv4ZVJ"
      },
      "source": [
        "To connect to your AlloyDB instance from this notebook, you will need to enable public IP on your instance. Alternatively, you can follow [these instructions](https://cloud.google.com/alloydb/docs/connect-external) to connect to an AlloyDB for PostgreSQL instance with Private IP from outside your VPC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPVWsQB04Yyl",
        "outputId": "3202ed19-f8c0-4c56-f1c8-2c0c22746221"
      },
      "outputs": [],
      "source": [
        "!gcloud beta alloydb instances update {instance_name} --region={region} --cluster={cluster_name} --assign-inbound-public-ip=ASSIGN_IPV4 --database-flags=\"password.enforce_complexity=on\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K86id-dcjcm"
      },
      "source": [
        "### Connect to AlloyDB\n",
        "\n",
        "This function will create a connection pool to your AlloyDB instance using the [AlloyDB Python connector](https://github.com/GoogleCloudPlatform/alloydb-python-connector). The AlloyDB Python connector will automatically create secure connections to your AlloyDB instance using mTLS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fYKVQzv2cjcm"
      },
      "outputs": [],
      "source": [
        "import asyncpg\n",
        "\n",
        "import sqlalchemy\n",
        "from sqlalchemy.ext.asyncio import AsyncEngine, create_async_engine\n",
        "\n",
        "from google.cloud.alloydb.connector import AsyncConnector, IPTypes\n",
        "\n",
        "async def init_connection_pool(connector: AsyncConnector, db_name: str, pool_size: int = 5) -> AsyncEngine:\n",
        "    # initialize Connector object for connections to AlloyDB\n",
        "    connection_string = f\"projects/{project_id}/locations/{region}/clusters/{cluster_name}/instances/{instance_name}\"\n",
        "\n",
        "    async def getconn() -> asyncpg.Connection:\n",
        "        conn: asyncpg.Connection = await connector.connect(\n",
        "            connection_string,\n",
        "            \"asyncpg\",\n",
        "            user=\"postgres\",\n",
        "            password=password,\n",
        "            db=db_name,\n",
        "            ip_type=IPTypes.PUBLIC,\n",
        "        )\n",
        "        return conn\n",
        "\n",
        "    pool = create_async_engine(\n",
        "        \"postgresql+asyncpg://\",\n",
        "        async_creator=getconn,\n",
        "        pool_size=pool_size,\n",
        "        max_overflow=0,\n",
        "    )\n",
        "    return pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_yNN1MnJpTR"
      },
      "source": [
        "### Create a Database\n",
        "\n",
        "Nex, you will create database to store the data using the connection pool. Enabling public IP takes a few minutes, you may get an error that there is no public IP address. Please wait and retry this step if you hit an error!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PX05ndo_AMc"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy.ext.asyncio import AsyncEngine, create_async_engine\n",
        "from sqlalchemy import text, exc\n",
        "\n",
        "from google.cloud.alloydb.connector import AsyncConnector, IPTypes\n",
        "\n",
        "async def create_db(database_name):\n",
        "    # Get a raw connection directly from the connector\n",
        "    connector = AsyncConnector()\n",
        "    connection_string = f\"projects/{project_id}/locations/{region}/clusters/{cluster_name}/instances/{instance_name}\"\n",
        "    pool = await init_connection_pool(connector, \"postgres\")\n",
        "    async with pool.connect() as conn:\n",
        "        try:\n",
        "          await conn.execute(text(\"COMMIT\")) # end transaction\n",
        "          await conn.execute(text(f\"CREATE DATABASE {database_name}\"))\n",
        "          print(f\"Database '{database_name}' created successfully\")\n",
        "        except exc.ProgrammingError:\n",
        "          print(f\"Database '{database_name}' already exists\")\n",
        "\n",
        "await create_db(database_name=database_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdolCWyatZmG"
      },
      "source": [
        "### Download data\n",
        "\n",
        "The following code has been prepared code to help insert the CSV data into your AlloyDB for PostgreSQL database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzr-2VZIkvtY"
      },
      "source": [
        "Download the CSV file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KkIQ2zSvQkN",
        "outputId": "624478f4-6902-46c2-f21e-99c6343824bf"
      },
      "outputs": [],
      "source": [
        "# TODO: Change cloud bucket\n",
        "!gsutil cp gs://cloud-samples-data/alloydb/investments_data /content/investments.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFU13dCBlYHh"
      },
      "source": [
        "The download can be verified by the following command or using the \"Files\" tab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQBs10I8vShh",
        "outputId": "e5f0d9ea-6ea6-40a7-ffd6-c5ea040348ab"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H7rorG9Ivur"
      },
      "source": [
        "In this next step you will:\n",
        "\n",
        "1. Create the table into store data\n",
        "2. And insert the data from the CSV into the database table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r16wPmxOBn_r"
      },
      "source": [
        "### Import data to your database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "v1pi9-8tB_pH"
      },
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "import pandas as pd\n",
        "\n",
        "data = \"/content/investments.csv\"\n",
        "\n",
        "df = pd.read_csv(data)\n",
        "df['etf'] = df['etf'].map({'t': True, 'f': False})\n",
        "df['rating'] = df['rating'].astype(str).fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "4R6tzuUtLypO",
        "outputId": "083ca96d-0437-4704-9ac3-12e4f3b59ab1"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UstTWGJyL7j-"
      },
      "source": [
        "The data consists of the following columns:\n",
        "\n",
        "* **id**\n",
        "* **ticker**: A string representing the stock symbol or ticker (e.g., \"AAPL\" for Apple, \"GOOG\" for Google).\n",
        "* **etf**: A boolean value indicating whether the asset is an ETF (True) or not (False).\n",
        "* **market**:  A string representing the stock exchange where the asset is traded.\n",
        "* **rating**: Whether to hold, buy or sell a stock.\n",
        "* **overview**: A text field for a general overview or description of the asset.\n",
        "* **analysis**: A text field, for a more detailed analysis of the asset.\n",
        "* **overview_embedding** (empty)\n",
        "* **analysis_embedding** (empty)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqpLkwbWCJaw"
      },
      "outputs": [],
      "source": [
        "create_table_cmd = sqlalchemy.text(\n",
        "    f'CREATE TABLE {table_name} ( \\\n",
        "    id SERIAL PRIMARY KEY, \\\n",
        "    ticker VARCHAR(255) NOT NULL UNIQUE, \\\n",
        "    etf BOOLEAN, \\\n",
        "    market VARCHAR(255), \\\n",
        "    rating TEXT,  \\\n",
        "    overview TEXT, \\\n",
        "    overview_embedding VECTOR (768), \\\n",
        "    analysis TEXT,  \\\n",
        "    analysis_embedding VECTOR (768) \\\n",
        "    )'\n",
        ")\n",
        "\n",
        "\n",
        "insert_data_cmd = sqlalchemy.text(\n",
        "    f\"\"\"\n",
        "    INSERT INTO {table_name} (id, ticker, etf, market,\n",
        "      rating, overview, analysis) VALUES (:id, :ticker, :etf, :market,\n",
        "      :rating, :overview, :analysis)\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "parameter_map = [\n",
        "    {\n",
        "        \"id\": row[\"id\"],\n",
        "        \"ticker\": row[\"ticker\"],\n",
        "        \"etf\": row[\"etf\"],\n",
        "        \"market\": row[\"market\"],\n",
        "        \"rating\": row[\"rating\"],\n",
        "        \"overview\": row[\"overview\"],\n",
        "        \"analysis\": row[\"analysis\"],\n",
        "    }\n",
        "    for index, row in df.iterrows()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCsM2KXbdYiv"
      },
      "outputs": [],
      "source": [
        "from google.cloud.alloydb.connector import AsyncConnector\n",
        "\n",
        "connector = AsyncConnector()\n",
        "\n",
        "# Create table and insert data\n",
        "async def insert_data(pool):\n",
        "  async with pool.connect() as db_conn:\n",
        "    await db_conn.execute(sqlalchemy.text(\"CREATE EXTENSION IF NOT EXISTS vector;\"))\n",
        "    await db_conn.execute(create_table_cmd)\n",
        "    await db_conn.execute(\n",
        "        insert_data_cmd,\n",
        "        parameter_map,\n",
        "    )\n",
        "    await db_conn.commit()\n",
        "\n",
        "pool = await init_connection_pool(connector, database_name)\n",
        "await insert_data(pool)\n",
        "await pool.dispose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaC8uhlfEwam"
      },
      "source": [
        "## Create the embeddings workflow\n",
        "\n",
        "The embeddings workflow contains four major parts:\n",
        "1. Read the data\n",
        "2. Batch the data\n",
        "3. Generate embeddings\n",
        "4. Update original table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIk5GxbnFaE3"
      },
      "source": [
        "#### Step 0:  Configure Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wvYGGRRoFXl4"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "# Configure the root logger to output messages with INFO level or above\n",
        "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='%(asctime)s[%(levelname)5s][%(name)14s] - %(message)s',  datefmt='%H:%M:%S', force=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekrEM22pJ2df"
      },
      "source": [
        "#### Step 1: Read the data\n",
        "\n",
        "This code reads data from a database and yields it for further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IZgMik9XBW19"
      },
      "outputs": [],
      "source": [
        "from typing import AsyncIterator, List\n",
        "from sqlalchemy import RowMapping\n",
        "from sqlalchemy.ext.asyncio import AsyncEngine\n",
        "\n",
        "async def get_source_data(pool: AsyncEngine, embed_cols: List[str]) -> AsyncIterator[RowMapping]:\n",
        "  \"\"\"\n",
        "  Yields data in the form of:\n",
        "      {'id' : 'id1', 'col1': 'val1', 'col2': 'val2'}\n",
        "  where col1 and col2 are columns containing data to be embedded.\n",
        "  \"\"\"\n",
        "  logger = logging.getLogger('get_source_data')\n",
        "\n",
        "  sql = f\"SELECT id, {', '.join(embed_cols)} FROM {table_name}\"\n",
        "  logger.info(f\"Running SQL query: {sql}\")\n",
        "  async with pool.connect() as conn:\n",
        "    async for row in await conn.stream(text(sql)):\n",
        "      logger.debug(f\"yielded row: {row._mapping['id']}\")\n",
        "      # Yield the row as a dictionary (RowMapping)\n",
        "      yield row._mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg54pvhjJ5kL"
      },
      "source": [
        "#### Step 2: Batch the data\n",
        "\n",
        "This code defines a function called `batch_source_data` that takes database rows and groups them into batches based on a character count limit (max_char_count). This batching process is crucial for efficient embedding generation for these reasons:\n",
        "\n",
        "* **Resource Optimization:**  Instead of sending numerous small requests, batching allows us to send fewer, larger requests. This significantly optimizes resource usage and potentially reduces API costs.\n",
        "\n",
        "* **Working Within API Limits:**  The max_char_count limit ensures each batch stays within the API's acceptable input size, preventing issues with exceeding the maximum character limit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "76qq6G38CZfm"
      },
      "outputs": [],
      "source": [
        "from typing import Any, List\n",
        "\n",
        "async def batch_source_data(read_generator: AsyncIterator[RowMapping]) ->  AsyncIterator[List[dict[str, Any]]]:\n",
        "  \"\"\"\n",
        "  Yields data in the form of:\n",
        "  [\n",
        "    {'id' : 'id1', 'col1': 'val1', 'col2': 'val2'},\n",
        "    ...\n",
        "  ]\n",
        "  where col1 and col2 are columns containing data to be embedded.\n",
        "  \"\"\"\n",
        "  logger = logging.getLogger('batch_data')\n",
        "\n",
        "  batch = []\n",
        "  char_count = 0\n",
        "  batch_num = 0\n",
        "\n",
        "  async for row in read_generator:\n",
        "    # Char count in current row\n",
        "    row_char_count = sum(len(row[col]) for col in cols_to_embed)\n",
        "\n",
        "    if char_count + row_char_count > max_char_count:\n",
        "        batch_num += 1\n",
        "        logger.info(f\"yielded batch number: {batch_num} with length: {len(batch)}\")\n",
        "        yield batch\n",
        "        batch, char_count = [], 0\n",
        "\n",
        "    # Add the current row to the batch\n",
        "    batch.append(row)\n",
        "    char_count += row_char_count\n",
        "\n",
        "  if batch:\n",
        "      batch_num += 1\n",
        "      logger.info(f\"Yielded batch number: {batch_num} with length: {len(batch)}\")\n",
        "      yield batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L4EnrleJ8gy"
      },
      "source": [
        "#### Step 3: Generate embeddings\n",
        "\n",
        "This step converts your text data into numerical representations called \"embeddings.\" These embeddings capture the meaning and relationships between words, making them useful for various tasks like search, recommendations, and clustering.\n",
        "\n",
        "The code uses two functions to efficiently generate embeddings:\n",
        "\n",
        "**embed_text**\n",
        "\n",
        "This function your text data and sends it to vertex AI, transforming the text in specific columns into embeddings.\n",
        "\n",
        "**embed_objects_concurrently**\n",
        "\n",
        "This function is the orchestrator. It manages the embedding generation process for multiple batches of text concurrently. This function ensures that all batches are processed efficiently without overwhelming the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4OYdrJk9Co0v"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from google.api_core.exceptions import ResourceExhausted\n",
        "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
        "\n",
        "async def embed_text(\n",
        "    logger: logging.Logger,\n",
        "    batch_data: List[dict[str, Any]],\n",
        "    model: TextEmbeddingModel,\n",
        "    cols_to_embed: List[str],\n",
        "    task_type: str = \"SEMANTIC_SIMILARITY\",\n",
        "    retries: int = 100,\n",
        "    delay: int = 1,\n",
        ") -> List[dict[str, List[float] | str]]:\n",
        "  \"\"\"\n",
        "  Returns data in the form of:\n",
        "  [\n",
        "    {\n",
        "      'id': 'id1',\n",
        "      'col1_embedding': [1.0, 1.1, ...],\n",
        "      'col2_embedding': [2.0, 2.1, ...],\n",
        "      ...\n",
        "    },\n",
        "    ...\n",
        "  ]\n",
        "  where col1 and col2 are columns containing data to be embedded.\n",
        "  \"\"\"\n",
        "  global total_char_count\n",
        "\n",
        "  # Place all of the embeddings into a single list\n",
        "  inputs = []\n",
        "  for data in batch_data:\n",
        "    inputs.extend(\n",
        "      TextEmbeddingInput(data[col], task_type) for col in cols_to_embed\n",
        "    )\n",
        "\n",
        "  for attempt in range(retries):  # Retry loop\n",
        "    try:\n",
        "      # Get embeddings for the text data\n",
        "      embeddings = await model.get_embeddings_async(inputs)\n",
        "\n",
        "      # Increase total char count\n",
        "      total_char_count += sum([len(input.text) for input in inputs])\n",
        "\n",
        "      # group the results together by id\n",
        "      embedding_iter = iter(embeddings)\n",
        "      results = []\n",
        "      for row in batch_data:\n",
        "        r = { 'id': row['id'] }\n",
        "        for col in cols_to_embed:\n",
        "          r[f'{col}_embedding'] = str(next(embedding_iter).values)\n",
        "        results.append(r)\n",
        "      return results\n",
        "\n",
        "    except ResourceExhausted as e:\n",
        "      if attempt < retries - 1:  # Retry only if attempts are left\n",
        "        logger.warning(f\"Error: {e}. Retrying in {delay} seconds...\")\n",
        "        await asyncio.sleep(delay)  # Wait before retrying\n",
        "      else:\n",
        "        logger.error(f\"Failed to get embeddings after {retries} attempts.\")\n",
        "        raise  # Raise the error if all retries fail\n",
        "\n",
        "  return []\n",
        "\n",
        "async def embed_objects_concurrently(\n",
        "    cols_to_embed: List[str],\n",
        "    batch_data: AsyncIterator[List[dict[str, Any]]],\n",
        "    model: TextEmbeddingModel,\n",
        "    task_type: str,\n",
        "    max_concurrency: int = 5,\n",
        ") -> AsyncIterator[List[dict[str, str | List[float]]]]:\n",
        "    \"\"\"\n",
        "    Embeds text from objects concurrently with a maximum concurrency limit. This\n",
        "    function processes batches of data concurrently, limiting the number of\n",
        "    simultaneous embedding tasks to improve efficiency and resource utilization.\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger('embed_objects')\n",
        "    # Keep track of pending tasks\n",
        "    pending: set[asyncio.Task] = set()\n",
        "    has_next = True\n",
        "    while pending or has_next:\n",
        "      while len(pending) < max_concurrency and has_next:\n",
        "        try:\n",
        "          data = await anext(batch_data)\n",
        "          coro = embed_text(logger, data, model, cols_to_embed, task_type)\n",
        "          pending.add(asyncio.ensure_future(coro))\n",
        "        except StopAsyncIteration:\n",
        "          has_next = False\n",
        "\n",
        "      done, pending = await asyncio.wait(\n",
        "          pending, return_when=asyncio.FIRST_COMPLETED\n",
        "      )\n",
        "\n",
        "      for task in done:\n",
        "        result = task.result()\n",
        "        logger.info(f\"Embedding task completed: Processed {len(result)} rows.\")\n",
        "        yield result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjErJPrJKA2j"
      },
      "source": [
        "#### Step 4: Update original table\n",
        "\n",
        "After generating embeddings for your text data, you need to store them in your database. This step efficiently updates your original table with the newly created embeddings.\n",
        "\n",
        "This process uses two functions to manage database updates:\n",
        "\n",
        "**batch_update_rows**\n",
        "1. This function takes a batch of data (including the embeddings) and updates the corresponding rows in your database table.\n",
        "2. It constructs an SQL UPDATE query to modify specific columns with the embedding values.\n",
        "3. It ensures that the updates are done efficiently and correctly within a database transaction.\n",
        "\n",
        "\n",
        "**batch_update_rows_concurrently**\n",
        "\n",
        "1. This function handles the concurrent updating of multiple batches of data.\n",
        "2. It creates multiple \"tasks\" that each execute the batch_update_rows function on a separate batch.\n",
        "3. It limits the number of concurrent tasks to avoid overloading your database and system resources.\n",
        "4. It manages the execution of these tasks, ensuring that all batches are processed efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "lEyvhlOCCr7F"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import text\n",
        "\n",
        "async def batch_update_rows(pool: AsyncEngine, logger: logging.Logger, data: List[dict[str, Any]]) -> None:\n",
        "  update_query = f\"\"\"\n",
        "    UPDATE {table_name}\n",
        "    SET {', '.join([f'{col}_embedding = :{col}_embedding' for col in cols_to_embed])}\n",
        "    WHERE id = :id;\n",
        "  \"\"\"\n",
        "\n",
        "  insert_params = []\n",
        "  for row in data:\n",
        "    insert_params.append({})\n",
        "\n",
        "  async with pool.connect() as conn:\n",
        "    await conn.execute(\n",
        "        text(update_query),\n",
        "        # Create parameters for all rows in the data\n",
        "        parameters = data,\n",
        "    )\n",
        "    await conn.commit()\n",
        "  logger.info(f\"Updated {len(data)} rows in database.\")\n",
        "\n",
        "\n",
        "async def batch_update_rows_concurrently(\n",
        "    pool: AsyncEngine,\n",
        "    embed_data: AsyncIterator[List[dict[str, Any]]],\n",
        "    max_concurrency: int = 5\n",
        "):\n",
        "  logger = logging.getLogger('update_rows')\n",
        "  # Keep track of pending tasks\n",
        "  pending: set[asyncio.Task] = set()\n",
        "  has_next = True\n",
        "  while pending or has_next:\n",
        "    while len(pending) < max_concurrency and has_next:\n",
        "      try:\n",
        "        data = await anext(embed_data)\n",
        "        coro = batch_update_rows(pool, logger, data)\n",
        "        pending.add(asyncio.ensure_future(coro))\n",
        "      except StopAsyncIteration:\n",
        "        has_next = False\n",
        "\n",
        "    done, pending = await asyncio.wait(\n",
        "        pending, return_when=asyncio.FIRST_COMPLETED\n",
        "    )\n",
        "\n",
        "  logger.info(\"All database update tasks completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSv4DwzbJc5J"
      },
      "source": [
        "## Run the embeddings workflow\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rWb1T9aIBWa-"
      },
      "outputs": [],
      "source": [
        "# Max token count for the embeddings API\n",
        "max_tokens = 20000\n",
        "\n",
        "# For some tokenizers and text, there's a rough approximation that 1 token corresponds to about 3-4 characters. This is a very general guideline and can vary significantly.\n",
        "max_char_count = max_tokens * 3\n",
        "\n",
        "cols_to_embed = ['analysis','overview']\n",
        "\n",
        "# Model to use for generating embeddings\n",
        "model_name = 'text-embedding-004'\n",
        "\n",
        "# Generate optimised embeddings for a given task\n",
        "# Ref: https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/task-types#supported_task_types\n",
        "task = \"SEMANTIC_SIMILARITY\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3FUBaXIUquR"
      },
      "source": [
        "This runs the complete embeddings workflow:\n",
        "\n",
        "1. Gettting source data\n",
        "2. Batching source data\n",
        "3. Generating embeddings for batches\n",
        "4. Updating data batches in the original table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syO1Zq3o5PnI",
        "outputId": "cfab522d-833d-4c66-dd45-76c1411e1b2e"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "import time\n",
        "import asyncio\n",
        "from vertexai.language_models import TextEmbeddingModel\n",
        "\n",
        "pool_size = 10\n",
        "embed_data_concurrency = 20\n",
        "batch_update_concurrency = 10\n",
        "total_char_count = 0\n",
        "\n",
        "# Set up connections to the database\n",
        "connector = AsyncConnector()\n",
        "pool = await init_connection_pool(connector, database_name, pool_size=pool_size)\n",
        "\n",
        "# Initialise VertexAI and the model to be used to generate embeddings\n",
        "vertexai.init(project=project_id, location=region)\n",
        "model = TextEmbeddingModel.from_pretrained(model_name)\n",
        "\n",
        "start_time = time.monotonic()\n",
        "\n",
        "# Fetch source data from the database\n",
        "source_data = get_source_data(pool, cols_to_embed)\n",
        "\n",
        "# Divide the source data into batches for efficient processing\n",
        "batch_data = batch_source_data(source_data)\n",
        "\n",
        "# Generate embeddings for the batched data concurrently\n",
        "embeddings_data = embed_objects_concurrently(cols_to_embed, batch_data, model, task, max_concurrency=embed_data_concurrency)\n",
        "\n",
        "# Update the database with the generated embeddings concurrently\n",
        "await batch_update_rows_concurrently(pool, embeddings_data, max_concurrency=batch_update_concurrency)\n",
        "\n",
        "end_time = time.monotonic()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "# Release database connections and close the connector\n",
        "await pool.dispose()\n",
        "await connector.close()\n",
        "\n",
        "print(f\"Job started at: {time.ctime(start_time)}\")\n",
        "print(f\"Job ended at: {time.ctime(end_time)}\")\n",
        "print(f\"Total run time: {elapsed_time:.2f} seconds\")\n",
        "print(f\"Total characters embedded: {total_char_count}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
