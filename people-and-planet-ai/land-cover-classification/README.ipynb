{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/GoogleCloudPlatform/python-docs-samples/main/people-and-planet-ai/land-cover-classification/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title My Google Cloud resources\n",
    "project = \"\" #@param {type:\"string\"}\n",
    "bucket = \"\" #@param {type:\"string\"}\n",
    "location = \"us-central1\" #@param {type:\"string\"}\n",
    "\n",
    "# Load from environment variables if available\n",
    "import os\n",
    "project = os.environ.get('GOOGLE_CLOUD_PROJECT', project)\n",
    "bucket = os.environ.get('CLOUD_STORAGE_BUCKET', bucket)\n",
    "location = os.environ.get('CLOUD_LOCATION', location)\n",
    "\n",
    "# Quick input validations\n",
    "assert project, 'âš ï¸ Please provide a Google Cloud project ID'\n",
    "assert bucket, 'âš ï¸ Please provide a Cloud Storage bucket name'\n",
    "assert not bucket.startswith('gs://'), f'âš ï¸ Please remove the gs:// prefix from the bucket name: {bucket}'\n",
    "assert location, 'âš ï¸ Please provide a Google Cloud location'\n",
    "\n",
    "# Workaround: Use legacy authentication method (b/229402252).\n",
    "os.environ['USE_AUTH_EPHEM'] = ''\n",
    "\n",
    "# Authenticate\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import google.auth\n",
    "\n",
    "credentials, _ = google.auth.default(\n",
    "    scopes=[\n",
    "        'https://www.googleapis.com/auth/cloud-platform',\n",
    "        'https://www.googleapis.com/auth/earthengine',\n",
    "    ]\n",
    ")\n",
    "ee.Initialize(credentials, project=project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFICATIONS = {\n",
    "    'ðŸ’§ Water':              '449cda',\n",
    "    'ðŸŒ³ Trees':              '3d7c49',\n",
    "    'ðŸŒ¾ Grass':              '8ab052',\n",
    "    'ðŸŒ¿ Flooded vegetation': '7c86c7',\n",
    "    'ðŸšœ Crops':              'e19832',\n",
    "    'ðŸª´ Shrub and scrub':    'dfc35b',\n",
    "    'ðŸ—ï¸ Built-up areas':     'c52918',\n",
    "    'ðŸª¨ Bare ground':        'a29d90',\n",
    "    'â„ï¸ Snow and ice':       'b4a0e0',\n",
    "}\n",
    "PALETTE = list(CLASSIFICATIONS.values())\n",
    "\n",
    "def display_legend():\n",
    "  reset_color = '\\u001b[0m'\n",
    "  colored = lambda red, green, blue: f\"\\033[48;2;{red};{green};{blue}m\"\n",
    "  for name, color in CLASSIFICATIONS.items():\n",
    "    red   = int(color[0:2], 16)\n",
    "    green = int(color[2:4], 16)\n",
    "    blue  = int(color[4:6], 16)\n",
    "    print(f\"{colored(red, green, blue)}   {reset_color} {name}\")\n",
    "\n",
    "display_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "def get_sentinel2_image(start_date: str, end_date: str) -> ee.Image:\n",
    "    def mask_sentinel2_clouds(image: ee.Image) -> ee.Image:\n",
    "        CLOUD_BIT = 10\n",
    "        CIRRUS_CLOUD_BIT = 11\n",
    "        bit_mask = (1 << CLOUD_BIT) | (1 << CIRRUS_CLOUD_BIT)\n",
    "        mask = image.select(\"QA60\").bitwiseAnd(bit_mask).eq(0)\n",
    "        return image.updateMask(mask)\n",
    "\n",
    "    return (\n",
    "        ee.ImageCollection(\"COPERNICUS/S2\")\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", 20))\n",
    "        .map(mask_sentinel2_clouds)\n",
    "        .median()\n",
    "    )\n",
    "\n",
    "sentinel2_image = get_sentinel2_image('2020-1-1', '2021-01-1')\n",
    "\n",
    "vis_params = {\n",
    "  'min': 0,\n",
    "  'max': 3000,\n",
    "  'bands': ['B4', 'B3', 'B2'],\n",
    "}\n",
    "folium.Map(\n",
    "    location=[38.6561723, -9.0624997],\n",
    "    zoom_start=12,\n",
    "    tiles=sentinel2_image.getMapId(vis_params)['tile_fetcher'].url_format,\n",
    "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "def get_landcover_image() -> ee.Image:\n",
    "    # Remap the ESA classifications into the Dynamic World classifications\n",
    "    fromValues = [10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100]\n",
    "    toValues = [1, 5, 2, 4, 6, 7, 8, 0, 3, 3, 7]\n",
    "    return (\n",
    "        ee.ImageCollection(\"ESA/WorldCover/v100\")\n",
    "        .first()\n",
    "        .select(\"Map\")\n",
    "        .remap(fromValues, toValues)\n",
    "        .rename(\"landcover\")\n",
    "    )\n",
    "\n",
    "landcover_image = get_landcover_image()\n",
    "\n",
    "vis_params = {\n",
    "  'bands': ['landcover'],\n",
    "  'palette': PALETTE,\n",
    "}\n",
    "folium.Map(\n",
    "    location=[38.6561723, -9.0624997],\n",
    "    zoom_start=12,\n",
    "    tiles=landcover_image.getMapId(vis_params)['tile_fetcher'].url_format,\n",
    "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Get the first row from the CSV to examine it.\n",
    "with open('data/points-small.csv') as f:\n",
    "  row = next(csv.DictReader(f))\n",
    "  coords = (float(row[\"lon\"]), float(row[\"lat\"]))\n",
    "  print(f\"coords as (lon, lat): {coords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "import io\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "INPUT_BANDS = [\"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\", \"B8\", \"B8A\", \"B9\", \"B10\", \"B11\", \"B12\"]\n",
    "OUTPUT_BANDS = [\"landcover\"]\n",
    "\n",
    "def get_patch(coords: Tuple[float, float], bands: List[str], patch_size: int, scale: int) -> np.ndarray:\n",
    "    sentinel2_image = get_sentinel2_image(\"2020-1-1\", \"2021-1-1\")\n",
    "    landcover_image = get_landcover_image()\n",
    "    image = sentinel2_image.addBands(landcover_image)\n",
    "\n",
    "    point = ee.Geometry.Point(coords)\n",
    "    url = image.getDownloadURL(\n",
    "        {\n",
    "            \"region\": point.buffer(scale * patch_size / 2, 1).bounds(1),\n",
    "            \"dimensions\": [patch_size, patch_size],\n",
    "            \"format\": \"NPY\",\n",
    "            \"bands\": bands,\n",
    "        }\n",
    "    )\n",
    "    np_bytes = requests.get(url, stream=True).content\n",
    "    return np.load(io.BytesIO(np_bytes), allow_pickle=True)\n",
    "\n",
    "sentinel2_image = get_sentinel2_image(\"2020-1-1\", \"2021-1-1\")\n",
    "landcover_image = get_landcover_image()\n",
    "image = sentinel2_image.addBands(landcover_image)\n",
    "\n",
    "patch = get_patch(coords, INPUT_BANDS + OUTPUT_BANDS, patch_size=8, scale=10)\n",
    "print(f\"patch shape={patch.shape} bands={len(patch.dtype)}\")\n",
    "print(f\"dtype: {patch.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def serialize(patch: np.ndarray) -> bytes:\n",
    "  features = {\n",
    "      name: tf.train.Feature(\n",
    "          float_list=tf.train.FloatList(value=patch[name].flatten())\n",
    "      )\n",
    "      for name in INPUT_BANDS + OUTPUT_BANDS\n",
    "  }\n",
    "  example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "  return example.SerializeToString()\n",
    "\n",
    "serialized = serialize(patch)\n",
    "print(f\"serialized: {type(serialized).__name__}[{len(serialized)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_patch_size = 8 #@param {type:\"integer\"}\n",
    "\n",
    "# Load from environment variables if available.\n",
    "training_patch_size = int(os.environ.get('TRAINING_PATCH_SIZE', training_patch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import random\n",
    "\n",
    "training_validation_ratio = [90, 10]\n",
    "\n",
    "def split_dataset(element, num_partitions) -> int:\n",
    "  return random.choices([0, 1], weights=training_validation_ratio)[0]\n",
    "\n",
    "with open(\"data/points-small.csv\") as f:\n",
    "  points = [(float(row[\"lon\"]), float(row[\"lat\"])) for row in csv.DictReader(f)]\n",
    "\n",
    "beam_options = PipelineOptions([], direct_num_workers=0)\n",
    "with beam.Pipeline(options=beam_options) as pipeline:\n",
    "  training_data, validation_data = (\n",
    "      pipeline\n",
    "      | \"Create points\" >> beam.Create(points)\n",
    "      | \"Get patch\" >> beam.Map(get_patch, INPUT_BANDS + OUTPUT_BANDS, training_patch_size, scale=10)\n",
    "      | \"Serialize\" >> beam.Map(serialize)\n",
    "      | \"Split dataset\" >> beam.Partition(split_dataset, 2)\n",
    "  )\n",
    "\n",
    "  training_data | \"Write training data\" >> beam.io.tfrecordio.WriteToTFRecord(\n",
    "      \"training-data\", file_name_suffix=\".tfrecord.gz\"\n",
    "  )\n",
    "  validation_data | \"Write validation data\" >> beam.io.tfrecordio.WriteToTFRecord(\n",
    "      \"validation-data\", file_name_suffix=\".tfrecord.gz\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "filenames = tf.data.Dataset.list_files(f\"training-data*.tfrecord.gz\")\n",
    "dataset = tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
    "for x in dataset.take(1):\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(x.numpy())\n",
    "  for _, feature in example.ListFields():\n",
    "    for _, field in feature.ListFields():\n",
    "      for name, values in sorted(field.items()):\n",
    "        print(f\"{name}: float[{len(values.float_list.value)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of classifications: {len(CLASSIFICATIONS)}\")\n",
    "print(f\"Training patch size: {training_patch_size}\")\n",
    "print(f\"Training patch area: {training_patch_size * training_patch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "def preprocess(patch: Dict[str, tf.Tensor]) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    inputs = tf.stack([patch[band] for band in INPUT_BANDS], axis=-1)\n",
    "    outputs = tf.one_hot(tf.cast(patch[\"landcover\"], tf.uint8), len(CLASSIFICATIONS))\n",
    "    return (inputs, outputs)\n",
    "\n",
    "input_shape = (training_patch_size, training_patch_size)\n",
    "features_dict = {\n",
    "    band_name: tf.io.FixedLenFeature(input_shape, tf.float32)\n",
    "    for band_name in INPUT_BANDS + OUTPUT_BANDS\n",
    "}\n",
    "\n",
    "def read_dataset(file_pattern: str) -> tf.data.Dataset:\n",
    "  return (\n",
    "      tf.data.Dataset.list_files(file_pattern)\n",
    "      .interleave(lambda filename: tf.data.TFRecordDataset(filename, compression_type=\"GZIP\"))\n",
    "      .batch(4)\n",
    "      .map(lambda batch: tf.io.parse_example(batch, features_dict))\n",
    "      .map(preprocess)\n",
    "  )\n",
    "\n",
    "training_dataset = read_dataset(f\"training-data*.tfrecord.gz\")\n",
    "validation_dataset = read_dataset(f\"validation-data*.tfrecord.gz\")\n",
    "for inputs, outputs in training_dataset.take(1):\n",
    "  print(f\"inputs:  {inputs.shape}\")\n",
    "  print(f\"outputs: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 5 #@param {type:\"integer\"}\n",
    "\n",
    "# Load from environment variables if available.\n",
    "kernel_size = int(os.environ.get('KERNEL_SIZE', kernel_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "normalization = tf.keras.layers.Normalization(name=\"Normalized\")\n",
    "normalization.adapt(training_dataset.map(lambda x, _: x))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(None, None, len(INPUT_BANDS)), name=\"Inputs\"),\n",
    "    normalization,\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=kernel_size, activation=\"relu\", name=\"Conv2D\"),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=kernel_size, activation=\"relu\", name=\"DeConv2D\"),\n",
    "    tf.keras.layers.Dense(len(CLASSIFICATIONS), activation=\"softmax\", name=\"LandCover\"),\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "    \n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    training_dataset.shuffle(10),\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=10,\n",
    ")\n",
    "model.save('local-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_patch_size = 64 #@param {type:\"integer\"}\n",
    "\n",
    "# Load from environment variables if available.\n",
    "prediction_patch_size = int(os.environ.get('PREDICTION_PATCH_SIZE', prediction_patch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io.filesystems import FileSystems\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import ee\n",
    "\n",
    "# The fire was in November 2018.\n",
    "years = [2017, 2018, 2019, 2020, 2021]\n",
    "\n",
    "regions = [\n",
    "    ('ðŸ”¥ Camp fire', {'lat': 39.7818, 'lon': -121.5124, 'year': year})\n",
    "    for year in years\n",
    "]\n",
    "\n",
    "def fetch_input_patch(name: str, region: Dict[str, float], patch_size: int = 256, scale: int = 10) -> None:\n",
    "  image = get_sentinel2_image(f\"{region['year']}-01-01\", f\"{region['year']}-12-31\")\n",
    "  point = ee.Geometry.Point([region['lon'], region['lat']])\n",
    "  url = image.getDownloadURL(\n",
    "      {\n",
    "          \"region\": point.buffer(scale * patch_size / 2, 1).bounds(1),\n",
    "          \"dimensions\": [patch_size, patch_size],\n",
    "          \"format\": \"NPY\",\n",
    "          \"bands\": INPUT_BANDS,\n",
    "      }\n",
    "  )\n",
    "  np_bytes = requests.get(url).content\n",
    "  structured_array = np.load(io.BytesIO(np_bytes), allow_pickle=True)\n",
    "  patch = np.stack([structured_array[band] for band in INPUT_BANDS], axis=-1)\n",
    "\n",
    "  filename = f\"predictions/{name}/{region['year']}.npz\"\n",
    "  with FileSystems.create(filename) as f:\n",
    "    np.savez_compressed(f, patch=patch)\n",
    "    print(f\"Created {filename}\")\n",
    "\n",
    "beam_options = PipelineOptions([], direct_num_workers=0)\n",
    "with beam.Pipeline(options=beam_options) as pipeline:\n",
    "  (\n",
    "      pipeline\n",
    "      | \"Create regions\" >> beam.Create(regions)\n",
    "      | \"Fetch patch\" >> beam.MapTuple(fetch_input_patch, prediction_patch_size, scale=10)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh \"predictions/ðŸ”¥ Camp fire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apache_beam.io.filesystems import FileSystems\n",
    "import numpy as np\n",
    "\n",
    "def load_patch(filename: str) -> np.ndarray:\n",
    "  with FileSystems.open(filename) as f:\n",
    "    return np.load(f)['patch']\n",
    "\n",
    "input_batch = np.stack([\n",
    "    load_patch(f\"predictions/ðŸ”¥ Camp fire/{year}.npz\")\n",
    "    for year in years\n",
    "])\n",
    "print(f\"input_batch: {input_batch.dtype} {input_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def render_rgb_images(values: np.ndarray, min=0.0, max=1.0, gamma=1.0) -> np.ndarray:\n",
    "  scaled_values = (values - min) / (max - min)\n",
    "  gamma_corrected_values = scaled_values ** (1.0 / gamma)\n",
    "  rgb_values = gamma_corrected_values * 255\n",
    "  return rgb_values.astype(np.uint8)\n",
    "\n",
    "def render_sentinel2(input_batch: np.ndarray) -> np.ndarray:\n",
    "  red   = input_batch[..., 3]  # B4\n",
    "  green = input_batch[..., 2]  # B3\n",
    "  blue  = input_batch[..., 1]  # B2\n",
    "  rgb_input_batch = np.stack([red, green, blue], axis=-1)\n",
    "  return render_rgb_images(rgb_input_batch, max=3000)\n",
    "\n",
    "sentinel2_images = render_sentinel2(input_batch)\n",
    "print(f\"sentinel2 images: {sentinel2_images.dtype} {sentinel2_images.shape}\")\n",
    "\n",
    "# Show one of the images to see how the Landsat input images look like.\n",
    "plt.imshow(sentinel2_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(f\"local-model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict(input_batch)\n",
    "print(f\"probabilities: {probabilities.dtype} {probabilities.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_classifications(probabilities: np.ndarray, palette: list) -> np.ndarray:\n",
    "  # Create a color map from a hex color palette.\n",
    "  xs = np.linspace(0, len(palette) - 1, 256)\n",
    "  indices = np.arange(len(palette))\n",
    "  color_map = np.array([\n",
    "        np.interp(xs, indices, [int(c[0:2], 16) for c in palette]),  # reds\n",
    "        np.interp(xs, indices, [int(c[2:4], 16) for c in palette]),  # greens\n",
    "        np.interp(xs, indices, [int(c[4:6], 16) for c in palette]),  # blues\n",
    "  ]).astype(np.uint8).transpose()\n",
    "\n",
    "  # Convert the probabilities into prediction indices and map them to the color map.\n",
    "  predictions = np.argmax(probabilities, axis=-1)\n",
    "  color_indices = (predictions / len(CLASSIFICATIONS) * 255).astype(np.uint8)\n",
    "  return np.take(color_map, color_indices, axis=0)\n",
    "\n",
    "def render_landcover(probabilities: np.ndarray) -> np.ndarray:\n",
    "  palette = list(CLASSIFICATIONS.values())\n",
    "  return render_classifications(probabilities, palette)\n",
    "\n",
    "# Render all our model probability predictions into RGB images.\n",
    "landcover_images = render_landcover(probabilities)\n",
    "print(f\"landcover images: {landcover_images.dtype} {landcover_images.shape}\")\n",
    "\n",
    "# Show one of the images to see how the land cover predictions look like.\n",
    "plt.imshow(landcover_images[0])\n",
    "\n",
    "display_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_land_cover_change(sentinel2_images: np.ndarray, landcover_images: np.ndarray):\n",
    "  img_size = 3\n",
    "  figsize = (img_size * len(years), img_size * 2)\n",
    "  figure, plot_rows = plt.subplots(2, len(years), figsize=figsize, sharex=True, sharey=True)\n",
    "  figure.tight_layout(pad=0)\n",
    "\n",
    "  for title, plot, image in zip(years, plot_rows[0], sentinel2_images):\n",
    "    plot.set_title(title if title != 2018 else '2018 (fire)')\n",
    "    plot.imshow(image)\n",
    "  for plot, image in zip(plot_rows[1], landcover_images):\n",
    "    plot.imshow(image)\n",
    "\n",
    "  display_legend()\n",
    "\n",
    "display_land_cover_change(sentinel2_images, landcover_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "from IPython.display import Image\n",
    "\n",
    "def land_cover_change_gif(sentinel2_images: np.ndarray, landcover_images: np.ndarray):\n",
    "  display_legend()\n",
    "\n",
    "  frames = np.concatenate([sentinel2_images, landcover_images], axis=2)\n",
    "  imageio.mimwrite('landcover-change.gif', frames, duration=1)\n",
    "  return Image(open('landcover-change.gif', 'rb').read())\n",
    "\n",
    "land_cover_change_gif(sentinel2_images, landcover_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd = [\n",
    "    f\"python\",\n",
    "    f\"create_datasets.py\",\n",
    "    f\"--training-file=gs://{bucket}/land-cover/training-data\",\n",
    "    f\"--validation-file=gs://{bucket}/land-cover/validation-data\",\n",
    "    f\"--patch-size={training_patch_size}\",\n",
    "    f\"--points-file=data/points.csv\",\n",
    "    f\"--runner=DataflowRunner\",\n",
    "    f\"--project={project}\",\n",
    "    f\"--region={location}\",\n",
    "    f\"--temp_location=gs://{bucket}/land-cover/temp\",\n",
    "    f\"--setup_file=./setup.py\",\n",
    "]\n",
    "subprocess.run(cmd, check=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
