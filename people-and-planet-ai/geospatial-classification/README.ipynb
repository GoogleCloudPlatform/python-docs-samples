{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "77c0f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Licensed to the Apache Software Foundation (ASF), Version 2.0 (the \"License\")\n",
    "\n",
    "# Licensed to the Apache Software Foundation (ASF) under one\n",
    "# or more contributor license agreements. See the NOTICE file\n",
    "# distributed with this work for additional information\n",
    "# regarding copyright ownership. The ASF licenses this file\n",
    "# to you under the Apache License, Version 2.0 (the\n",
    "# \"License\"); you may not use this file except in compliance\n",
    "# with the License. You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing,\n",
    "# software distributed under the License is distributed on an\n",
    "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "# KIND, either express or implied. See the License for the\n",
    "# specific language governing permissions and limitations\n",
    "# under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683a5f8",
   "metadata": {},
   "source": [
    "# ðŸ­ Power Plant ON/OFF: Predictions\n",
    "\n",
    "* **Time estimate**: 1 hour\n",
    "* **Cost estimate**: less than **5**.00 USD\n",
    "\n",
    "This is an **interactive** notebook that contains **all** of the **code** necessary to train an ML model from satellite images for a geospatial classification of whether a power plant is on/off. \n",
    "\n",
    "This is a first step **introductory example** of how this **satellite images** can be used to detect **carbon pollution** from power plants.\n",
    "\n",
    "--------------------------------------------\n",
    "\n",
    "\n",
    "ðŸ’š This is one of many **machine learning how-to samples** inspired from **real climate solutions** aired on the [People and Planet AI ðŸŽ¥ series](https://www.youtube.com/playlist?list=PLIivdWyY5sqI-llB35Dcb187ZG155Rs_7)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922968ad",
   "metadata": {},
   "source": [
    "# ðŸš Overview\n",
    "\n",
    "This notebook leverages geospatial data from [Google Earth Engine](https://earthengine.google.com/) and labeled data provided by the organization [Climate TRACE](https://www.climatetrace.org/). By combining these two data sources, you'll build and train a model that predicts whether or not a power plant is turned on and producing emissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15adff",
   "metadata": {},
   "source": [
    "### ðŸ›°ï¸ Data _(inputs)_\n",
    "\n",
    "The data in this example consists of images from a satellite called [Sentinel-2](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2#description), for a wide-swath, **high-resolution**, multi-spectral imaging for land monitoring studies.\n",
    "\n",
    "When working with satellite data, each input image has the **dimensions** `[width, height, bands]`. **Bands** are measurements from specific satellite instruments for different ranges of the **electromagnetic spectrum**. For example, Sentinel-2 contains [ðŸŒˆ 13 spectral bands](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2#bands). If you are familiar with image classification problems, you can think of the bands as similar to an image's RGB (red, green, blue) channels. However, when working with satellite data we generally have **more than just 3** channels.\n",
    "\n",
    "![satellite_inputs](img/inputs.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15be296",
   "metadata": {},
   "source": [
    "### ðŸ·ï¸ Labels _(outputs)_\n",
    "\n",
    "For each patch of pixels (an image of a power plant) that we give to the model, it performs **binary classification**, which indicates whether the power plant is on or off.\n",
    "\n",
    "In this example, the **output** is a single number between *0 (Off) and 1 (On)*, representing the **probability** of that power plant being ON.\n",
    "\n",
    "![satellite_outputs](img/outputs.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce50bc",
   "metadata": {},
   "source": [
    "### Model _(function)_\n",
    "\n",
    "**TL;DR**\n",
    "*The model will receive a patch of pixels, in the center is the power plant tower. We then take 16 pixels as padding creating a 33x33 patch. This returns a classification of ON/OFF*\n",
    "\n",
    "In this example, we have a CSV file of labels. Each row in this file represents a power plant at a specific lat/lon and timestamp. To deal with the sparsity, at training time we'll prepare a dataset where each input image is a single pixel that we have a label for. We will then add a padding around that image. These padded pixels will not get predictions, but will help our model to make better predictions for the center point that we have a label for.\n",
    "\n",
    "For example, with a padding of 16, each 1 pixel input point would become a 33x33 image after the padding is added.\n",
    "\n",
    "![training](img/training.png)\n",
    "\n",
    "\n",
    "At prediction time, we can pass in an image of any size. We'll add a layer of padding around the image, and will get predictions for each pixel except for the padding.\n",
    "\n",
    "To handle the variable input size, we'll use a fully convolutional neural network. Using this type of architecture will allow us to have variable input image sizes. Note that while the height and width of the image can be variable, the number of bands must be constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3547aec6",
   "metadata": {},
   "source": [
    "## ðŸš´â€â™€ï¸ Steps summary\n",
    "\n",
    "Here's a quick summary of what youâ€™ll go through:\n",
    "\n",
    "1. **Get the training data**:\n",
    "  Extract satellite images from [Earth Engine](https://earthengine.google.com/), combine it with the data that was labeled and contains lat/long coordinates from [Climate TRACE](https://climatetrace.org) in a CSV, and export to\n",
    "  [Cloud Storage](https://cloud.google.com/storage).\n",
    "\n",
    "1. **Run a custom training job**:\n",
    "  Using [Tensorflow Keras](https://keras.io/) on [Vertex AI Training](https://cloud.google.com/vertex-ai/docs/training/custom-training) using a [pre-built training container](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers).\n",
    "\n",
    "1. **Deploy a web service to host the trained model**:\n",
    "  On\n",
    "  [Cloud Run](https://cloud.google.com/run)\n",
    "  and get predictions using the model.\n",
    "\n",
    "1. **Get Predictions**:\n",
    "  Use the web service to get predictions for new data.\n",
    "\n",
    "1. **Visualize predictions**:\n",
    "  Visualize the preductions on a map.\n",
    "\n",
    "1. (Optional) **Delete the project** to avoid ongoing costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b21577",
   "metadata": {},
   "source": [
    "## ðŸ™ˆ Using this interactive notebook\n",
    "\n",
    "Click the **run** icons â–¶ï¸ of each section within this notebook. \n",
    "\n",
    "This notebook code lets you train and deploy an ML model, as well as test its accuracy, from end-to-end. When you run a code cell, the code runs in the notebook's runtime, so you're not making any changes to your personal computer.\n",
    "\n",
    "> ðŸ›Žï¸ **To avoid any errors**, wait for each section to finish in their order before clicking the next â€œrunâ€ icon.\n",
    "\n",
    "This sample must be connected to a **Google Cloud project**, but nothing else is needed other than your Google Cloud project.\n",
    "You can use an existing project and the cost will be less than **$5.00**. Alternatively, you can create a new Cloud project with cloud credits for free"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0033a40",
   "metadata": {},
   "source": [
    "## âœ¨ Before you begin, you need toâ€¦\n",
    "\n",
    "1. Decide on creating a new\n",
    "   [free project](https://cloud.google.com/free/docs/gcp-free-tier)\n",
    "   _(recommended)_ or using an existing one.\n",
    "   Then **copy the project ID** and paste it in the `google_cloud_project` field in the \"Entering project detailsâ€ section below.\n",
    "\n",
    "   > ðŸ’¡ If you _don't plan to keep the resources_ that you create via this sample, we recommend creating a new project instead of selecting an existing project.\n",
    "   > After you finish these steps, you can delete the project, removing all the resources associated in bulk.\n",
    "\n",
    "1. [_Click here_](https://console.cloud.google.com/flows/enableapi?apiid=dataflow,aiplatform.googleapis.com)\n",
    "   to **enable the following APIs** in your Google Cloud project:\n",
    "   _Dataflow_ and _AI Platform_.\n",
    "\n",
    "1. Make sure that **billing is enabled** for your Google Cloud project,\n",
    "   [_click here_](https://cloud.google.com/billing/docs/how-to/modify-project)\n",
    "   to learn how to confirm that billing is enabled.\n",
    "\n",
    "1. Have an **Earth Engine** account (it's FREE) or create a new one.\n",
    "  To create an account, fill out the [registration form here.](https://signup.earthengine.google.com/#!/). Please note this can take from 0-24 hours...but it's worth it! Come back to this sample after you have this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ab72c",
   "metadata": {},
   "source": [
    "### â›ï¸ Preparing the project environment\n",
    "\n",
    "Click the run â–¶ï¸ icons in order for the cells to download and install the necessary code, libraries, and resources for this solution.\n",
    "\n",
    "> ðŸ’¡ You can _optionally_ view the entire\n",
    "> [code in GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/tree/main/people-and-planet-ai/geospatial-classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a363277-2195-42b4-83e7-3e3921bb3db1",
   "metadata": {},
   "source": [
    "### â†˜ï¸ Install the Vertex AI SDK\n",
    "\n",
    "Note that you will be prompted to restart the runtime after installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc25399d-7d5d-4050-9442-2ef2c7d83e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --user --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dffaaf-5321-47e7-9dfa-ff82cd0e6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45965fcc-2ff1-4b27-8c20-6f6af7667271",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=project, staging_bucket=bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34fdd8",
   "metadata": {},
   "source": [
    "### â†˜ï¸ Get the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c2848f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sample source code.\n",
    "\n",
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b439f-03bb-427f-ae61-4d6d5f066d15",
   "metadata": {},
   "source": [
    "### âœï¸ Enter your Cloud project's details. Ensure you provide a regional bucket!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246702e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title My Google Cloud resources\n",
    "project = '' #@param {type:\"string\"}\n",
    "bucket = '' #@param {type:\"string\"}\n",
    "region = 'us-central1' #@param {type:\"string\"}\n",
    "\n",
    "# Validate the inputs.\n",
    "if not project:\n",
    "  raise ValueError(f\"Please provide a value for 'project'\")\n",
    "if not bucket:\n",
    "  raise ValueError(f\"Please provide a value for 'bucket'\")\n",
    "if not region:\n",
    "  raise ValueError(f\"Please provide a value for 'region'\")\n",
    "\n",
    "# Authenticate\n",
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()\n",
    "print('Authenticated')\n",
    "\n",
    "!gcloud config set project {project}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec73dd9",
   "metadata": {},
   "source": [
    "### ðŸ—ºï¸ Authenticate to Earth Engine\n",
    "\n",
    "In order to use the Earth Engine API, you'll **need** to have an **Earth Engine account**.\n",
    "\n",
    "To create an account, fill out the [registration form here.](https://signup.earthengine.google.com/#!/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb4cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b0418",
   "metadata": {},
   "source": [
    "# 1. ðŸ›°ï¸ Get the training data\n",
    "\n",
    "The training data in this sample comes from **two places**: \n",
    "\n",
    "1. The satellite images will be extracted from *Earth Engine*.\n",
    "\n",
    "2. The **labels** are provided in a *CSV file* that indicates whether a *power plant* is turned *on or off* at a **particular timestamp**. \n",
    "\n",
    "For each row in the CSV file, we need to extract the corresponding Sentinel image taken at that specific latitude/longitude and timestamp. We'll **export** this image data, along with the corresponding label (on/off), to Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0dd3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "94f60a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "\n",
    "BANDS = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B10', 'B11', 'B12']\n",
    "LABEL = 'is_powered_on'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba81d1",
   "metadata": {},
   "source": [
    "### ðŸ·ï¸ Import labels\n",
    "\n",
    "First, we **import** the **CSV** file that contains the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "42190dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dataframe = pd.read_csv('labeled_geospatial_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdb7d16-a9c7-4be8-b403-ccb10dcad261",
   "metadata": {},
   "source": [
    "Each row in this dataframe represents a power plant at a particular timestamp. \n",
    "\n",
    "The label column indicates whether or not the power plant was turned **on (1)** or **off (0)** at that timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe94b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa51b23",
   "metadata": {},
   "source": [
    "Next, we import this data into an Earth Engine [`Feature Collection`](https://developers.google.com/earth-engine/apidocs/ee-featurecollection).\n",
    "\n",
    "In Earth Engine, a [`Feature`](https://developers.google.com/earth-engine/guides/features) is an object with a _geometry property_ storing a [`Geometry`](https://developers.google.com/earth-engine/guides/geometries) object, and a _properties property_ storing a dictionary of other properties. Groups of related `Features` can be combined into a `FeatureCollection` to enable additional operations on the entire set such as filtering, sorting, and rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "3a8b42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_fc(path):\n",
    "  '''Creates a FeatureCollection from the label dataframe.'''\n",
    "\n",
    "  dataframe = pd.read_csv(path)\n",
    "  num_examples = dataframe.shape[0]\n",
    "  data_dict = dataframe.to_dict()\n",
    "  feats = []\n",
    "  properties = ['timestamp', 'is_powered_on']\n",
    "  for idx in np.arange(num_examples):\n",
    "    feat_dict = {}\n",
    "    geometry = ee.Geometry.Point([data_dict['lon'][idx], data_dict['lat'][idx]])  \n",
    "    for feature in properties:\n",
    "      feat_dict[feature] = data_dict[feature][idx]\n",
    "    feat = ee.Feature(geometry, feat_dict)\n",
    "    feats.append(feat)\n",
    "  return ee.FeatureCollection(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "6eb9f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_fc = create_label_fc('labeled_geospatial_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb421ba4-c9b1-4d81-b543-656766fac47c",
   "metadata": {},
   "source": [
    "Let's take a look at the first element in the `FeatureCollection`. You can see that this is equivalent to the first element in our dataframe, but just in a different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "eeb5b6c2-4f53-481b-96d1-07a39415988a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'geometry': {'coordinates': [-84.80529, 39.11613], 'type': 'Point'},\n",
      " 'id': '0',\n",
      " 'properties': {'label': 1, 'timestamp': '2020-07-03 16:32:41.397000+00:00'},\n",
      " 'type': 'Feature'}\n"
     ]
    }
   ],
   "source": [
    "pprint(label_fc.first().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc8b4a2",
   "metadata": {},
   "source": [
    "Next, we define a preprocessing function that will reformat the timestamp into two new properties: `start` and `end`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "264aea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(feature):\n",
    "  '''Creates start date and end date properties.'''\n",
    "    \n",
    "  # Extract start and end dates\n",
    "  timestamp = ee.String(feature.get('timestamp')).split(' ').get(0)\n",
    "  year =  ee.Number.parse(ee.String(timestamp).split('-').get(0))\n",
    "  month = ee.Number.parse(ee.String(timestamp).split('-').get(1))\n",
    "  day =   ee.Number.parse(ee.String(timestamp).split('-').get(2))\n",
    "  start = ee.Date.fromYMD(year, month, day)\n",
    "  end = start.advance(1, 'day')\n",
    "\n",
    "  # Create new feature\n",
    "  feature = feature.set({'start': start, 'end': end})\n",
    "\n",
    "  return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a35408-f7f1-46bd-a73f-db4a48538313",
   "metadata": {},
   "source": [
    "We map this preprocessing function across our `FeatureCollection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "3132cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_fc = label_fc.map(format_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4524d75",
   "metadata": {},
   "source": [
    "Let's examine the first feature in this collection to see what it looks like after the map operation. \n",
    "\n",
    "You can see that each feature has a `Geometry`, which is a specific latitude and longitude, as well as a set of properties:\n",
    "\n",
    "* `label` indicates whether the power plant is on (1) or off (0)\n",
    "* `start` is the datetime for when this observation was made\n",
    "* `end` is a datetime one day after `start`\n",
    "* `timestamp` is the original timestamp pulled from the CSV file\n",
    "\n",
    "The `label` property is what we want our model to predict. And the `start` and `end` timestamps will be helpful when we extract the corresponding Sentinel images because each label is for a specific point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "01cc0ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'geometry': {'coordinates': [-84.80529, 39.11613], 'type': 'Point'},\n",
      " 'id': '0',\n",
      " 'properties': {'end': {'type': 'Date', 'value': 1593820800000},\n",
      "                'label': 1,\n",
      "                'start': {'type': 'Date', 'value': 1593734400000},\n",
      "                'timestamp': '2020-07-03 16:32:41.397000+00:00'},\n",
      " 'type': 'Feature'}\n"
     ]
    }
   ],
   "source": [
    "pprint(label_fc.first().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96967303",
   "metadata": {},
   "source": [
    "### Merge ðŸ·ï¸ labels + ðŸ›°ï¸ Sentinel image data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa236af4",
   "metadata": {},
   "source": [
    "In Earth Engine, an [`ImageCollection`](https://developers.google.com/earth-engine/guides/ic_creating) is a stack or sequence of images. An [`Image`](https://developers.google.com/earth-engine/guides/image_overview) is composed of one or more bands and each band has its own name, data type, scale, mask and projection. The [`Sentinel-2`](https://developers.google.com/earth-engine/guides/ic_creating) dataset is represented as an `ImageCollection`, where each image in the collection is of a specific geographic location at a particular time.\n",
    "\n",
    "In the cell below, we write a function to extract the Sentinel image taken at the specific latitude/longitude and timestamp for each `Feature` in our `FeatureCollection`. \n",
    "\n",
    "To do this, we first filter the Sentinel-2 `ImageCollection` at the start/end dates for a particular `Feature`.\n",
    "\n",
    "Then, using the [`neighorboodToArray`](https://developers.google.com/earth-engine/api_docs#eeimageneighborhoodtoarray) method we create a new `FeatureCollection` that contains the satellite data for each band at the latitude and longitude of interest as well as a 16 pixel padding around that point.\n",
    "\n",
    "In the image below you can think of the purple box representing the lat/lon where the power plant is located. And around this pixel, we add the padding.\n",
    "\n",
    "![training](img/training.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "a93f1947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighboring_patch(feature):\n",
    "  '''Gets image pixel values for patch.'''\n",
    "    \n",
    "  # filter ImageCollection at start/end dates.   \n",
    "  image = ee.ImageCollection('COPERNICUS/S2').filterDate(\n",
    "      feature.get('start'), feature.get('end')).select(BANDS).median()\n",
    "  \n",
    "  # extract pixel values at the lat/lon with a 16x16 padding\n",
    "  return ee.FeatureCollection([\n",
    "      image.neighborhoodToArray(ee.Kernel.square(16)).sampleRegions(\n",
    "          collection=ee.FeatureCollection([feature]), scale=10).first()\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7a95a7",
   "metadata": {},
   "source": [
    "We map this function across the `FeatureCollection` and flatten it so we have a single `FeatureCollection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "6d85ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = label_fc.map(get_neighboring_patch).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21267b05-38cc-4f14-ab09-197baef26713",
   "metadata": {},
   "source": [
    "Let's look at the properties for the first element in this new `FeatureCollection`. You can see that it still contains the `start`, `end`, `label`, and `timestamp` properties, but with  has 13 additional properies, one for each spectral band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "69933ee9-8aa0-49f7-ad33-c0b17db329bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system:index',\n",
       " 'start',\n",
       " 'end',\n",
       " 'label',\n",
       " 'timestamp',\n",
       " 'B10',\n",
       " 'B11',\n",
       " 'B12',\n",
       " 'B8A',\n",
       " 'B1',\n",
       " 'B2',\n",
       " 'B3',\n",
       " 'B4',\n",
       " 'B5',\n",
       " 'B6',\n",
       " 'B7',\n",
       " 'B8',\n",
       " 'B9']"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.first().propertyNames().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79c514-ad63-4b85-8da2-ab8967fe8d5a",
   "metadata": {},
   "source": [
    "The data contained in each band property is an array of shape 33x33.\n",
    "\n",
    "For example, here is the data for band B1 in the first element of our `FeatureCollection` expressed as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "a70c127e-7c45-4eab-914d-17a0c3a9e42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1803 1803 1803 ... 1797 1797 1797]\n",
      " [1803 1803 1803 ... 1797 1797 1797]\n",
      " [1803 1803 1803 ... 1797 1797 1797]\n",
      " ...\n",
      " [1519 1519 1519 ... 1560 1560 1560]\n",
      " [1519 1519 1519 ... 1560 1560 1560]\n",
      " [1519 1519 1519 ... 1560 1560 1560]]\n",
      "shape: (33, 33)\n"
     ]
    }
   ],
   "source": [
    "example_feature = np.array(data.first().get('B1').getInfo())\n",
    "print(example_feature)\n",
    "print('shape: ' + str(example_feature.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab1318d",
   "metadata": {},
   "source": [
    "### ðŸŽ›ï¸ Create train/validation splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cca925",
   "metadata": {},
   "source": [
    "Before we can train an ML model, we need to split this data into training and validation datasets. We can easily do this by adding a random column to our `FeatureCollection` and then filtering the collection on that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "6b4483b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.randomColumn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "4f2b67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% of data for training and 30% for validation\n",
    "\n",
    "training = data.filter(ee.Filter.lt('random', 0.7))\n",
    "validation = data.filter(ee.Filter.gte('random', 0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02607c8",
   "metadata": {},
   "source": [
    "### ðŸ’¾ Export data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c87eb9",
   "metadata": {},
   "source": [
    "Lastly, we'll export the data to a Cloud Storage bucket. We'll export the data as [TFRecords](https://www.tensorflow.org/tutorials/load_data/tfrecord) and only export the bands and label properties.\n",
    "\n",
    "Later when we run the training job, we'll parse these TFRecords and feed them to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "53f2d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data\n",
    "\n",
    "training_task = ee.batch.Export.table.toCloudStorage(\n",
    "  collection=training,\n",
    "  description=\"Training image export\",\n",
    "  bucket=bucket,\n",
    "  fileNamePrefix=\"geospatial_training\",\n",
    "  selectors= BANDS + [LABEL],\n",
    "  fileFormat='TFRecord')\n",
    "\n",
    "training_task.start()\n",
    "\n",
    "validation_task = ee.batch.Export.table.toCloudStorage(\n",
    "  collection=validation,\n",
    "  description=\"Validation image export\",\n",
    "  bucket=bucket,\n",
    "  fileNamePrefix=\"geospatial_validation\",\n",
    "  selectors= BANDS + [LABEL],\n",
    "  fileFormat='TFRecord')\n",
    "\n",
    "validation_task.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadeab16",
   "metadata": {},
   "source": [
    "This export will take around 35 minutes. You can monitor the progress with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d111251",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(ee.batch.Task.list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1b9dd",
   "metadata": {},
   "source": [
    "# 2. ðŸ‘Ÿ Run a custom training job\n",
    "\n",
    "Once the export jobs have finished, we're **ready to use** that data to train a model on Vertex AI Training.\n",
    "\n",
    "The complete training code can be found in the `task.py` file.\n",
    "\n",
    "To run our custom training job on Vertex AI Training, we'll use the [pre-built containers](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers) provided by Vertex AI to run our training script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b99054-b843-485e-9cf0-c9f8ae739d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.CustomTrainingJob(\n",
    "    display_name=\"geospatial_model_training\",\n",
    "    script_path=\"task.py\",\n",
    "    container_uri=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-7:latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4baff79-0347-4452-afaa-9c042472f837",
   "metadata": {},
   "source": [
    "The job will take around 10 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5893ce1d-cdbe-43fa-98cc-221a7a2530d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = job.run(args=[f'--bucket={bucket}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75499ed",
   "metadata": {},
   "source": [
    "# 3. ðŸ’»Deploy a web service to host the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cbab39",
   "metadata": {},
   "source": [
    "Next, we use\n",
    "[Cloud Run](https://cloud.google.com/run)\n",
    "to deploy a web service that exposes a\n",
    "[REST API](https://en.wikipedia.org/wiki/Representational_state_transfer) to\n",
    "get predictions from our trained model.\n",
    "\n",
    "To run the web service, we configure Cloud Run to launch\n",
    "[`gunicorn`](https://gunicorn.org)\n",
    "on the container image we built.\n",
    "\n",
    "We also provide environment variables with the Google Cloud project ID, a Cloud Storage path, a Compute Engine region, as well as the container image itself.\n",
    "These are the Google Cloud resources we want the web service to use when launching new jobs or creating new resources.\n",
    "\n",
    "Since calls to this web service could launch potentially expensive jobs in our project, we configure it to _only_ accept authenticated calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e28bff-0804-4093-acf2-739700b24c5f",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Build container\n",
    "\n",
    "We use Cloud Build to build the container image. After the image is built, it is available in Container Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ba749-b325-4700-ace9-c1c5af3996aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Container Registry path for the sample container image.\n",
    "app_container_image = f\"gcr.io/{project}/geospatial-classification/app\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c8774f-b90d-47d8-8453-f01e05594751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and push the container image.\n",
    "# https://cloud.google.com/sdk/gcloud/reference/builds/submit\n",
    "!gcloud builds submit serving_app \\\n",
    "  --tag=\"{app_container_image}\" \\\n",
    "  --machine-type \"e2-highcpu-8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9978056f-4467-4dda-85a5-84655ade9a11",
   "metadata": {},
   "source": [
    "## ðŸ£ Deploy app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c299f1-e108-46bd-8b12-06af56a88444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the web service to Cloud Run.\n",
    "# https://cloud.google.com/sdk/gcloud/reference/run/deploy\n",
    "!gcloud run deploy \"geospatial-service\" \\\n",
    "  --image=\"{app_container_image}\" \\\n",
    "  --command=\"gunicorn\" \\\n",
    "  --args=\"--threads=8,--timeout=0,main:app\" \\\n",
    "  --region=\"us-central1\" \\\n",
    "  --memory=\"1G\" \\\n",
    "  --no-allow-unauthenticated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a32d4bf-4345-43f7-9371-aa151ad4f521",
   "metadata": {},
   "source": [
    "Now we need the web service URL to make calls to the REST API we just exposed. We can use `gcloud run services describe` to get the web service URL.\n",
    "\n",
    "Since we only accept authorized calls in our web service, we also need to authenticate each call.\n",
    "`gcloud` is already authenticated, so we can use `gcloud auth print-identity-token` to get quick access.\n",
    "\n",
    "> â„¹ï¸ For more information on how to do authenticated calls in Cloud Run, see the\n",
    "> [Authentication overview](https://cloud.google.com/run/docs/authenticating/overview) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f5e5e3-d5dd-4cb7-bb38-5b2e3b439ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Get the web service URL.\n",
    "#   https://cloud.google.com/sdk/gcloud/reference/run/services/describe\n",
    "service_url = subprocess.run(\n",
    "    [ 'gcloud', 'run', 'services', 'describe', 'geospatial-service',\n",
    "        f'--region={region}',\n",
    "        f'--format=get(status.url)',\n",
    "    ],\n",
    "    capture_output=True,\n",
    ").stdout.decode('utf-8').strip()\n",
    "print(f\"service_url: {service_url}\")\n",
    "\n",
    "# Get an identity token for authorized calls to our web service.\n",
    "#   https://cloud.google.com/sdk/gcloud/reference/auth/print-identity-token\n",
    "identity_token = subprocess.run(\n",
    "    ['gcloud', 'auth', 'print-identity-token'],\n",
    "    capture_output=True,\n",
    ").stdout.decode('utf-8').strip()\n",
    "print(f\"identity_token: {identity_token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c4dfe-b55d-4f80-a7eb-9ee86542ce59",
   "metadata": {},
   "source": [
    "Finally, we can test that everything is working.\n",
    "\n",
    "We included a `ping` method in our web service just to *make sure everything is working* as expected.\n",
    "It simply returns back the arguments we passed to the call, as well as a response saying that the call was successful.\n",
    "\n",
    "> ðŸ›Žï¸ This is a convenient way to make sure the web service is reachable, the authentication is working as expected, and the request arguments are passed correctly.\n",
    "\n",
    "We can use Python's\n",
    "[`requests`](https://docs.python-requests.org)\n",
    "library.\n",
    "The web service was built to always accept [JSON](https://www.w3schools.com/whatis/whatis_json.asp)-encoded requests, and returns JSON-encoded responses.\n",
    "\n",
    "For a **request to be successful**, it **must**:\n",
    "\n",
    "* Be an [`HTTP POST`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/POST) request\n",
    "* Contain the following **headers**:\n",
    "  * `Authorization: Bearer IDENTITY_TOKEN`\n",
    "  * `Content-Type: application/json`\n",
    "* The data must be **valid JSON**, if *no arguments* are needed we can pass `{}` as an **empty object**.\n",
    "\n",
    "For **ease of use**, `requests.post` has a\n",
    "[`json` parameter](https://docs.python-requests.org/en/master/user/quickstart/#more-complicated-post-requests)\n",
    "that **automatically attaches the header** `Content-Type: application/json` and encodes our data into a JSON string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "1395bd18-e6eb-47cf-b0ca-7d7d04cce8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "9025db3b-d409-46cf-9ce2-6f0209dfbea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'args': 'Hello world!', 'response': 'Your request was successful! ðŸŽ‰'}"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(\n",
    "    url=f'{service_url}/ping',\n",
    "    headers={'Authorization': f'Bearer {identity_token}'},\n",
    "    json={'x': 42, 'message': 'Hello world!'},\n",
    ").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d64a22-887a-4469-9ba3-668ec23f8667",
   "metadata": {},
   "source": [
    "# 4.ðŸ”® Get Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b7bf1-cf07-4a93-9cf3-0f9f31c13fa9",
   "metadata": {},
   "source": [
    "Now that we know our app is up and running, we can use it to make predictions.\n",
    "\n",
    "Let's start by making a prediction for a particular power plant. To do this we will need to extract the Sentinel data from Earth Engine and send it in the body of the post requst to the prediction service.\n",
    "\n",
    "We'll start with a plant located at the coordinates -84.80529, 39.11613, and then extract the satellite data from October 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "a7f6b8c2-cab3-4030-8528-9afe644a800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "570f7e8f-6f68-4433-aa29-ce0e3e4cd604",
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_location = ee.Feature(ee.Geometry.Point([-84.80529, 39.11613]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "9e477289-398c-4bcb-ab23-aee65ac92388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image data\n",
    "\n",
    "def get_prediction_data(feature, start, end):\n",
    "  '''Extracts Sentinel image as json at specific lat/lon and timestamp.'''\n",
    "\n",
    "  image = ee.ImageCollection('COPERNICUS/S2').filterDate(start, end).select(BANDS).mosaic()\n",
    "\n",
    "  fc = ee.FeatureCollection([\n",
    "        image.neighborhoodToArray(ee.Kernel.square(16)).sampleRegions(\n",
    "            collection=ee.FeatureCollection([feature]), scale=10).first()\n",
    "    ])\n",
    "  \n",
    "  # download FeatureCollection as JSON\n",
    "  url = fc.getDownloadURL('geojson')\n",
    "  bytes = requests.get(url).content\n",
    "  values=bytes.decode(\"utf-8\")\n",
    "  json_values = json.loads(values)\n",
    "  return json_values['features'][0]['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "86d53ea1-b09e-4afb-8d04-60b73ec59c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = get_prediction_data(plant_location, '2021-10-01', '2021-10-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d93aaa8",
   "metadata": {},
   "source": [
    "The prediction service **expects two things** the **input data** for the prediction as well as the Cloud Storage **path** where the model is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "5c01631e-5607-45c8-a42e-354fb38a87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.post(\n",
    "    url=f'{service_url}/predict',\n",
    "    headers={'Authorization': f'Bearer {identity_token}'},\n",
    "    json={'data': prediction_data, 'bucket': bucket},\n",
    ").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222aaf9",
   "metadata": {},
   "source": [
    "# 4. ðŸ—ºï¸ Visualize predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fd0a5-a1ae-4cac-91cc-342809d9fb3b",
   "metadata": {},
   "source": [
    "Let's visualize the results of a power plant in Spain. First, we get predictions for the four towers at this power plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "ac680e7f-3598-422a-af5e-bb666425dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [ee.Feature(ee.Geometry.Point([-7.86444, 43.43717])),\n",
    "             ee.Feature(ee.Geometry.Point([-7.86376, 43.43827])),\n",
    "             ee.Feature(ee.Geometry.Point([-7.85755, 43.44075])),\n",
    "             ee.Feature(ee.Geometry.Point([-7.85587, 43.44114])),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "9fc56972-47bb-4b37-b447-400cbea5e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_predictions = []\n",
    "for location in locations:\n",
    "    prediction_data = get_prediction_data(location, '2021-10-01', '2021-10-31')\n",
    "    result = requests.post(\n",
    "        url=f'{service_url}/predict',\n",
    "        headers={'Authorization': f'Bearer {identity_token}'},\n",
    "        json={'data': prediction_data, 'bucket': bucket},).json()\n",
    "    preds.append(result['predictions']['predictions'][0][0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be593a27-71b1-4ea1-8c2e-100a0a82ccdd",
   "metadata": {},
   "source": [
    "Next, we can **plot** these points on a map. **Red** means our model predicts that the towers are **\"on\"**, and **blue** means that it predicts the towers are **\"off\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "98651a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import folium.plugins as folium_plugins\n",
    "import branca.colormap as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "4a0b6bc2-e187-4d0c-90de-636f47db6b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = [-7.86444, -7.86376, -7.85755, -7.85587]\n",
    "lat = [43.43717, 43.43827, 43.44075, 43.44114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ba038b-49c9-40bf-8d87-af7d253d270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = cm.LinearColormap(colors=['red','lightblue'], index=[90,100], vmin=90, vmax=100)\n",
    "map = folium.Map([43.45, -7.87], zoom_start=14, tiles='CartoDB positron')\n",
    "for loc, p in zip(zip(lat, lon), preds):\n",
    "    folium.Circle(\n",
    "        location=loc,\n",
    "        radius=20,\n",
    "        fill=True,\n",
    "        color=colormap(p),\n",
    "    ).add_to(map)\n",
    "\n",
    "map.add_child(colormap)\n",
    "\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcabd53-e81e-4d72-a453-e2fb6dcaa7ae",
   "metadata": {},
   "source": [
    "# 6. ðŸ§¹ Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002e48a-035c-4369-a161-aa2d800a70b2",
   "metadata": {},
   "source": [
    "To **avoid incurring charges** to your Google Cloud account for the resources used in this tutorial, either delete the project that contains the resources, or keep the project and delete the individual resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc97850-80dd-4c24-80d0-f93825d96e0e",
   "metadata": {},
   "source": [
    "## Deleting the project\n",
    "\n",
    "The **easiest** way to **eliminate billing** is to delete the project that you created for the tutorial.\n",
    "\n",
    "To delete the project:\n",
    "\n",
    "> âš ï¸ Deleting a project has the following effects:\n",
    ">\n",
    "> * **Everything in the project is deleted.** If you used an existing project for this tutorial, when you delete it, you also delete any other work you've done in the project.\n",
    ">\n",
    "> * **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in the future. To preserve the URLs that use the project ID, such as an appspot.com URL, delete selected resources inside the project instead of deleting the whole project.\n",
    ">\n",
    "> If you plan to explore multiple tutorials and quickstarts, **reusing** projects can help you avoid exceeding project **quota limits**.\n",
    "\n",
    "1. In the Cloud Console, go to the **Manage resources** page.\n",
    "\n",
    "  <button>\n",
    "\n",
    "  [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects)\n",
    "\n",
    "  </button>\n",
    "\n",
    "1. In the project list, select the project that you want to delete, and then click **Delete**.\n",
    "\n",
    "1. In the dialog, type the project ID, and then click **Shut down** to delete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1c51a-ef84-4645-91ae-b997e1643170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
