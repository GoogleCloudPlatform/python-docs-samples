{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j1pdgkM2PA9a",
      "metadata": {
        "cellView": "form",
        "id": "j1pdgkM2PA9a"
      },
      "outputs": [],
      "source": [
        "#@title ###### Licensed to the Apache Software Foundation (ASF), Version 2.0 (the \"License\")\n",
        "\n",
        "# Licensed to the Apache Software Foundation (ASF) under one\n",
        "# or more contributor license agreements. See the NOTICE file\n",
        "# distributed with this work for additional information\n",
        "# regarding copyright ownership. The ASF licenses this file\n",
        "# to you under the Apache License, Version 2.0 (the\n",
        "# \"License\"); you may not use this file except in compliance\n",
        "# with the License. You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing,\n",
        "# software distributed under the License is distributed on an\n",
        "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "# KIND, either express or implied. See the License for the\n",
        "# specific language governing permissions and limitations\n",
        "# under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "orng0uT9-8iT",
      "metadata": {
        "id": "orng0uT9-8iT"
      },
      "source": [
        "# ðŸ”¥ Wildfire spread forecasting -- Overview\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GoogleCloudPlatform/python-docs-samples/blob/main/people-and-planet-ai/wildfires-forecasting/notebooks/1-overview.ipynb)\n",
        "\n",
        "In 2021, wildfires destroyed [7 million acres of wildland](https://www.ncei.noaa.gov/access/monitoring/monthly-report/fire/202113)--roughly the same area as the state of Massachusetts. These wildfires destroyed homes, towns, and people's lives.\n",
        "\n",
        "<figure>\n",
        "<img alt=\"Exterior image of a house mostly destroyed by flames\"\n",
        "     src=\"https://media.cnn.com/api/v1/images/stellar/prod/200908110238-07-wildfires-0907-malden-wa.jpg?q=x_17,y_443,h_876,w_1556,c_crop/h_720,w_1280\"/>\n",
        "<figcaption><i>Figure. The 2020 Babb Road wildfire destroying a home in Malden, WA</i></figcaption>\n",
        "</figure>\n",
        "\n",
        "\n",
        "For a wildfire to catch hold and spread, a set of conditions must exist in an environment. These conditions have been measured and recorded in multiple sources--sources that are available in Earth Engine. Imagine if you could build a ML model that can predict the likelihood and spread of wildfires!\n",
        "\n",
        "This sample is broken into the following notebooks:\n",
        "\n",
        "* ðŸ§­ **Overview**. Go through what we want to achieve and explore the data we want to use as inputs and outputs for our model.\n",
        "* ðŸ—„ï¸ [**Create the dataset**](https://colab.research.google.com/github/GoogleCloudPlatform/python-docs-samples/blob/main/people-and-planet-ai/wildfires-forecasting/notebooks/2-dataset.ipynb) Use [Apache Beam](https://beam.apache.org/) to fetch data from [Earth Engine](https://earthengine.google.com/) and create a dataset for our model in [Dataflow](https://cloud.google.com/dataflow).\n",
        "* ðŸ§  **Train the model**: Build a simple _Fully Convolutional Network_ in [PyTorch](https://pytorch.org/) and train it in [Vertex AI](https://cloud.google.com/vertex-ai/docs/training/custom-training) with the dataset we created.\n",
        "* ðŸ”® **Model predictions**: Get predictions from the model with data it has never seen before.\n",
        "\n",
        "This sample leverages geospatial satellite and topographical data from [Google Earth Engine](https://earthengine.google.com/). Using satellite imagery, you'll build and train a model for predicting the potentials spread of a \"current\" wildfire.\n",
        "\n",
        "+ â²ï¸ Time estimate: TT hours\n",
        "+ ðŸ’° Cost estimate: Around \\\\$DD USD (free if you use \\\\$300 Cloud credits)\n",
        "\n",
        "ðŸ’š This is one of many machine learning how-to samples inspired from real climate solutions aired on the People and Planet AI ðŸŽ¥ series."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jsWGZW_fUJjN",
      "metadata": {
        "id": "jsWGZW_fUJjN"
      },
      "source": [
        "## ðŸ“’ Using this interactive notebook\n",
        "\n",
        "Click the **run** icons â–¶ï¸ of each section within this notebook.\n",
        "\n",
        "![Run cell](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/ppai-fires/people-and-planet-ai/wildfires-forecasting/notebooks/data/images/run-cell.png?raw=1)\n",
        "\n",
        "> ðŸ’¡ Alternatively, you can run the currently selected cell with `Ctrl + Enter` (or `âŒ˜ + Enter` in a Mac).\n",
        "\n",
        "This **notebook code lets you train and deploy an ML model** from end-to-end. When you run a code cell, the code runs in the notebook's runtime, so you're not making any changes to your personal computer.\n",
        "\n",
        "> âš ï¸ **To avoid any errors**, wait for each section to finish in their order before clicking the next â€œrunâ€ icon.\n",
        "\n",
        "This sample must be connected to a **Google Cloud project**, but nothing else is needed other than your Google Cloud project.\n",
        "\n",
        "You can use an existing project or you can create a new Cloud project [with cloud credits for free.](https://cloud.google.com/free/docs/gcp-free-tier)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DgtZrFNdP3lv",
      "metadata": {
        "id": "DgtZrFNdP3lv"
      },
      "source": [
        "## ðŸŽ¬ Before you begin\n",
        "\n",
        "Let's start by cloning the GitHub repository and installing some dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8630578-6629-4a04-a08b-98b9d2577ce5",
      "metadata": {
        "id": "e8630578-6629-4a04-a08b-98b9d2577ce5"
      },
      "outputs": [],
      "source": [
        "# Now let's get the code from GitHub and navigate to the sample.\n",
        "!git clone https://github.com/GoogleCloudPlatform/python-docs-samples.git\n",
        "%cd python-docs-samples/people-and-planet-ai/weather-forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e0a851e-4829-4dfd-b006-4ec1201f8029",
      "metadata": {
        "id": "4e0a851e-4829-4dfd-b006-4ec1201f8029"
      },
      "source": [
        "# â˜ï¸ My Google Cloud resources\n",
        "\n",
        "First, choose the Google Cloud _location_ where you want to run this sample.\n",
        "A good place to start is by choosing your [Google Cloud location](https://cloud.google.com/compute/docs/regions-zones).\n",
        "\n",
        "> âš ï¸ Make sure you choose a location\n",
        "> available for all products: [Cloud Storage](https://cloud.google.com/storage/docs/locations),\n",
        "> [Vertex AI](https://cloud.google.com/vertex-ai/docs/general/locations),\n",
        "> [Dataflow](https://cloud.google.com/dataflow/docs/resources/locations), and\n",
        "> [Cloud Run](https://cloud.google.com/run/docs/locations).\n",
        "\n",
        "> ðŸ’¡ Prefer locations that are geographically closer to you with\n",
        "> [low carbon emissions](https://cloud.google.com/sustainability/region-carbon), highlighted with the\n",
        "> ![Leaf](https://cloud.google.com/sustainability/region-carbon/gleaf.svg) icon.\n",
        "\n",
        "Make sure you have followed these steps to configure your Google Cloud project:\n",
        "\n",
        "1. Enable the APIs: _Dataflow, Earth Engine, Vertex AI, and Cloud Run_\n",
        "\n",
        "  <button>\n",
        "\n",
        "  [Click here to enable the APIs](https://console.cloud.google.com/flows/enableapi?apiid=dataflow.googleapis.com,earthengine.googleapis.com,aiplatform.googleapis.com,run.googleapis.com)\n",
        "  </button>\n",
        "\n",
        "1. Create a Cloud Storage bucket in your desired _location_.\n",
        "\n",
        "  <button>\n",
        "\n",
        "  [Click here to create a new Cloud Storage bucket](https://console.cloud.google.com/storage/create-bucket)\n",
        "  </button>\n",
        "\n",
        "1. Register your\n",
        "  [Compute Engine default service account](https://console.cloud.google.com/iam-admin/iam)\n",
        "  on Earth Engine.\n",
        "\n",
        "  <button>\n",
        "\n",
        "  [Click here to register your service account on Earth Engine](https://signup.earthengine.google.com/#!/service_accounts)\n",
        "  </button>\n",
        "\n",
        "Once you have everything ready, you can go ahead and fill in your Google Cloud resources in the following code cell.\n",
        "Make sure you run it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0e776c9a-64c2-4bba-b17a-dbe9a4814224",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e776c9a-64c2-4bba-b17a-dbe9a4814224",
        "outputId": "9b1b1ffe-dc40-4d4e-e1aa-8abd0393f53c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Please fill in these values.\n",
        "project = \"video-erschmid\" #@param {type:\"string\"}\n",
        "\n",
        "# Load values from environment variables if available.\n",
        "project = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", project)\n",
        "\n",
        "# Quick input validations.\n",
        "assert project, \"âš ï¸ Please provide a Google Cloud project ID\"\n",
        "\n",
        "# Configure gcloud.\n",
        "!gcloud config set project {project}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fUX87ic-uNNI",
      "metadata": {
        "id": "fUX87ic-uNNI"
      },
      "source": [
        "Next, we have to authenticate Earth Engine and initialize it.\n",
        "Since we've already authenticated to this [Colab](https://www.youtube.com/watch?v=rNgswRZ2C1Y) and saved our credentials as the [Google default credentials](https://google-auth.readthedocs.io/en/master/reference/google.auth.html#google.auth.default),\n",
        "we can reuse those credentials for Earth Engine.\n",
        "\n",
        "> ðŸ’¡ Since we're making **large amounts of automated requests to Earth Engine**, we want to use the\n",
        "[high-volume endpoint](https://developers.google.com/earth-engine/cloud/highvolume)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3TV2ZvLH17If",
      "metadata": {
        "id": "3TV2ZvLH17If"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import google.auth\n",
        "\n",
        "def ee_init() -> None:\n",
        "    \"\"\"Authenticate and initialize Earth Engine with the default credentials.\"\"\"\n",
        "    # Use the Earth Engine High Volume endpoint.\n",
        "    #   https://developers.google.com/earth-engine/cloud/highvolume\n",
        "    credentials, _ = google.auth.default(\n",
        "        scopes=[\n",
        "            \"https://www.googleapis.com/auth/cloud-platform\",\n",
        "            \"https://www.googleapis.com/auth/earthengine\",\n",
        "        ]\n",
        "    )\n",
        "    ee.Initialize(\n",
        "        credentials,\n",
        "        project=project,\n",
        "        opt_url=\"https://earthengine-highvolume.googleapis.com\",\n",
        "    )\n",
        "\n",
        "ee_init()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6V2XkHeNNMb_",
      "metadata": {
        "id": "6V2XkHeNNMb_"
      },
      "source": [
        "# ðŸ§­ Overview\n",
        "\n",
        "Before we begin, let's consider what we want to achieve and the datasets we chose for that purpose. The goal of our model is to use satellite images to forecastd the areas surrounding an active wildfire to which the wildfire might spread. We will use satellite images to predict what areas around a wildfire might likely catch on fire within a set period of time (1 day).\n",
        "\n",
        "When working with satellite data, each image has the shape `(widht, height, bands)`. **Bands** contain _numeric values_ for each pixel in the image, like the measurements from specific satellite instruments for different ranges of the electromagnetic spectrum or the probabilities of different classifications. If you're familiar with classification problems, you can think of the bands as similar to an image's RGB channels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aqGsEZBf6ASC",
      "metadata": {
        "id": "aqGsEZBf6ASC"
      },
      "source": [
        "## ðŸ›° Inputs: Satellite images\n",
        "\n",
        "To achieve our goal, we must combine multiple geographical datasets into a single dataset (or map in this case). Each input--also known as \"features\" or \"independent variables\"--will be stored as a single band within the resulting map. The following list shows the datasets used for this example:\n",
        "\n",
        "* **USGS/SRTMGL1_003**: NASA SRTM Digital Elevation 30m\n",
        "* **GRIDMET/DROUGHT**: CONUS Drought Indices\n",
        "* **ECMWF/ERA5/DAILY**: Daily Aggregates - Latest Climate Reanalysis Produced by ECMWF / Copernicus Climate Change Service\n",
        "* **IDAHO_EPSCOR/GRIDMET**: University of Idaho Gridded Surface Meteorological Dataset\n",
        "* **CIESIN/GPWv411/GPW_Population_Density**: Population Density (Gridded Population of the World Version 4.11)\n",
        "\n",
        "The following table shows the model input variables, the source dataset, and the symbols used for variable in our model.\n",
        "\n",
        "| Feature | Original Source | Variable name |\n",
        "| --------|:----------------|:--------------|\n",
        "| Elevation | `USGS/SRTMGL1_003` | `elevation` |\n",
        "| Palmer Drought Severity Index | `GRIDMET/DROUGHT` | `psdi` |\n",
        "| Avg air temperature at 2m height | `ECMWF/ERA5/DAILY` | `mean_2m_air_temperature` |\n",
        "| Total precipitation | `ECMWF/ERA5/DAILY` | `total_precipitation` |\n",
        "| 10m u-component of wind (daily avg) | `ECMWF/ERA5/DAILY` | `u_component_of_wind_10m` |\n",
        "| 10m v-component of wind (daily avg) | `ECMWF/ERA5/DAILY` | `v_component_of_wind_10m'` |\n",
        "|\n",
        "| Precipatation amount | `IDAHO_EPSCOR/GRIDMET` | `pr` |\n",
        "| Specific humidity | `IDAHO_EPSCOR/GRIDMET` | `sph` |\n",
        "| Wind direction | `IDAHO_EPSCOR/GRIDMET` | `th` |\n",
        "| Minimum temperature | `IDAHO_EPSCOR/GRIDMET` | `tmmn` |\n",
        "| Maximum temperature | `IDAHO_EPSCOR/GRIDMET` | `tmmx` |\n",
        "| Wind velocity at 10m | `IDAHO_EPSCOR/GRIDMET` | `vs` |\n",
        "| Energy release component | `IDAHO_EPSCOR/GRIDMET` | `erc` |\n",
        "| Population density (per square km) | `CIESIN/GPWv411/GPW_Population_Density` | `population_density` |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JNpQO_6UQDOt",
      "metadata": {
        "id": "JNpQO_6UQDOt"
      },
      "outputs": [],
      "source": [
        "INPUTS = {\n",
        "    'USGS/SRTMGL1_003': [\"elevation\"],\n",
        "    'GRIDMET/DROUGHT': [\"psdi\"],\n",
        "    'ECMWF/ERA5/DAILY': [\n",
        "         'mean_2m_air_temperature',\n",
        "         'total_precipitation',\n",
        "         'u_component_of_wind_10m',\n",
        "         'v_component_of_wind_10m'],\n",
        "    'IDAHO_EPSCOR/GRIDMET': [\n",
        "         'pr',\n",
        "         'sph',\n",
        "         'th',\n",
        "         'tmmn',\n",
        "         'tmmx',\n",
        "         'vs',\n",
        "         'erc'],\n",
        "    'CIESIN/GPWv411/GPW_Population_Density': ['population_density'],\n",
        "    'MODIS/006/MOD14A1': ['FireMask']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "s_j0UGCkZavj",
      "metadata": {
        "id": "s_j0UGCkZavj"
      },
      "source": [
        "## ðŸ—º **Outputs**: Land cover map\n",
        "\n",
        "Finally, we need to give the model a set of labels to apply to each section of the map. These labels tell the training program (PyTorch) what we want to infer from the previous data. In other words, this dataset represents the \"dependent variable\" that our model attempts to predict. For our model, we will use the \"Terra Thermal Anomalies & Fire Daily Global 1km (MODIS/006/MOD14A1)\" map from Earth Engine. We'll use the band `FireMask` provided by the map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a_xR5-c0ZhlN",
      "metadata": {
        "id": "a_xR5-c0ZhlN"
      },
      "outputs": [],
      "source": [
        "LABELS = {\n",
        "    'MODIS/006/MOD14A1': ['FireMask'],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“š Explore the data\n",
        "\n",
        "Let's take a closer look at our inputs and outputs to understand what the data looks like. We'll look at a handful of selections of satellite images to see what each band from the maps provide.\n",
        "\n",
        "To get the data from Earth Engine, we'll use this helper function `get_image()`."
      ],
      "metadata": {
        "id": "nBN5wk_59YVh"
      },
      "id": "nBN5wk_59YVh"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image(\n",
        "    date: datetime, bands_schema: Dict[str, List[str]], window: timedelta\n",
        ") -> ee.Image:\n",
        "    ee_init()\n",
        "    # if elevation dataset is part of bands_schema, deal with it separately\n",
        "    if 'USGS/SRTMGL1_003' in bands_schema:\n",
        "      elevation = ee.Image('USGS/SRTMGL1_003').select(bands_schema['USGS/SRTMGL1_003'])\n",
        "      bands_schema.pop(\"USGS/SRTMGL1_003\")\n",
        "    else:\n",
        "      elevation = None\n",
        "\n",
        "    # if population dataset is part of bands_schema, deal with it separately\n",
        "    if 'CIESIN/GPWv411/GPW_Population_Density' in bands_schema:\n",
        "      population = [\n",
        "          ee.ImageCollection('CIESIN/GPWv411/GPW_Population_Density')\n",
        "        .filterDate(date.isoformat(), (date + window).isoformat())\n",
        "        .select(bands_schema['CIESIN/GPWv411/GPW_Population_Density'])\n",
        "        .median()\n",
        "      ]\n",
        "      bands_schema.pop(\"CIESIN/GPWv411/GPW_Population_Density\")\n",
        "    else:\n",
        "      population = None\n",
        "\n",
        "    images = [\n",
        "        ee.ImageCollection(collection)\n",
        "        .filterDate(date.isoformat(), (date + window).isoformat())\n",
        "        .select(bands)\n",
        "        .mosaic()\n",
        "        for collection, bands in bands_schema.items()\n",
        "    ]\n",
        "    # add elevation to list\n",
        "    if elevation:\n",
        "      images.append(elevation)\n",
        "    # add population to list\n",
        "    if population:\n",
        "      images.append(population)\n",
        "    return ee.Image(images)"
      ],
      "metadata": {
        "id": "Vu1nPIpO9ayF"
      },
      "id": "Vu1nPIpO9ayF",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Labels"
      ],
      "metadata": {
        "id": "P3PVxYpf-O0Q"
      },
      "id": "P3PVxYpf-O0Q"
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "import folium\n",
        "\n",
        "date = datetime(2019, 6, 4)\n",
        "delta = timedelta(days=1.0)\n",
        "point = {\n",
        "    \"long\": -119.81,\n",
        "    \"lat\": 46.85\n",
        "}\n",
        "\n",
        "image = get_image(date, LABELS, delta)\n",
        "map = folium.Map([point[\"long\"], point[\"lat\"]], zoom_start=5)\n",
        "\n",
        "print(image)"
      ],
      "metadata": {
        "id": "vGFlHkJp7ngD",
        "outputId": "d0a245b7-8905-4267-e139-7204e493d24d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vGFlHkJp7ngD",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ee.Image({\n",
            "  \"functionInvocationValue\": {\n",
            "    \"functionName\": \"ImageCollection.mosaic\",\n",
            "    \"arguments\": {\n",
            "      \"collection\": {\n",
            "        \"functionInvocationValue\": {\n",
            "          \"functionName\": \"Collection.map\",\n",
            "          \"arguments\": {\n",
            "            \"baseAlgorithm\": {\n",
            "              \"functionDefinitionValue\": {\n",
            "                \"argumentNames\": [\n",
            "                  \"_MAPPING_VAR_0_0\"\n",
            "                ],\n",
            "                \"body\": {\n",
            "                  \"functionInvocationValue\": {\n",
            "                    \"functionName\": \"Image.select\",\n",
            "                    \"arguments\": {\n",
            "                      \"bandSelectors\": {\n",
            "                        \"constantValue\": [\n",
            "                          \"FireMask\"\n",
            "                        ]\n",
            "                      },\n",
            "                      \"input\": {\n",
            "                        \"argumentReference\": \"_MAPPING_VAR_0_0\"\n",
            "                      }\n",
            "                    }\n",
            "                  }\n",
            "                }\n",
            "              }\n",
            "            },\n",
            "            \"collection\": {\n",
            "              \"functionInvocationValue\": {\n",
            "                \"functionName\": \"Collection.filter\",\n",
            "                \"arguments\": {\n",
            "                  \"collection\": {\n",
            "                    \"functionInvocationValue\": {\n",
            "                      \"functionName\": \"ImageCollection.load\",\n",
            "                      \"arguments\": {\n",
            "                        \"id\": {\n",
            "                          \"constantValue\": \"MODIS/006/MOD14A1\"\n",
            "                        }\n",
            "                      }\n",
            "                    }\n",
            "                  },\n",
            "                  \"filter\": {\n",
            "                    \"functionInvocationValue\": {\n",
            "                      \"functionName\": \"Filter.dateRangeContains\",\n",
            "                      \"arguments\": {\n",
            "                        \"leftValue\": {\n",
            "                          \"functionInvocationValue\": {\n",
            "                            \"functionName\": \"DateRange\",\n",
            "                            \"arguments\": {\n",
            "                              \"end\": {\n",
            "                                \"constantValue\": \"2019-06-05T00:00:00\"\n",
            "                              },\n",
            "                              \"start\": {\n",
            "                                \"constantValue\": \"2019-06-04T00:00:00\"\n",
            "                              }\n",
            "                            }\n",
            "                          }\n",
            "                        },\n",
            "                        \"rightField\": {\n",
            "                          \"constantValue\": \"system:time_start\"\n",
            "                        }\n",
            "                      }\n",
            "                    }\n",
            "                  }\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "})\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "environment": {
      "kernel": "python3",
      "name": "common-cu110.m103",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cu110:m103"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}